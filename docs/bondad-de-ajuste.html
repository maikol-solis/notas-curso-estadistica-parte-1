<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 13 Bondad de ajuste | Notas Curso de Estadística (Parte I)</title>
  <meta name="description" content="Capítulo 13 Bondad de ajuste | Notas Curso de Estadística (Parte I)" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 13 Bondad de ajuste | Notas Curso de Estadística (Parte I)" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 13 Bondad de ajuste | Notas Curso de Estadística (Parte I)" />
  
  
  

<meta name="author" content="Maikol Solís" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="prueba-de-comparación-de-medias-en-2-poblaciones.html"/>
<link rel="next" href="tablas-de-contingencia.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html"><i class="fa fa-check"></i><b>2</b> Inferencia estadística</a>
<ul>
<li class="chapter" data-level="2.1" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#ejemplo"><i class="fa fa-check"></i><b>2.1</b> Ejemplo</a></li>
<li class="chapter" data-level="2.2" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#modelo-estadístico"><i class="fa fa-check"></i><b>2.2</b> Modelo estadístico</a></li>
<li class="chapter" data-level="2.3" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#estadístico"><i class="fa fa-check"></i><b>2.3</b> Estadístico</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><i class="fa fa-check"></i><b>3</b> Densidades previas conjugadas y estimadores de Bayes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-previa-distribución-a-priori"><i class="fa fa-check"></i><b>3.1</b> Distribución previa (distribución a priori)</a></li>
<li class="chapter" data-level="3.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#densidad-posterior"><i class="fa fa-check"></i><b>3.2</b> Densidad posterior</a></li>
<li class="chapter" data-level="3.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#proceso-de-modelación-de-parámetros."><i class="fa fa-check"></i><b>3.3</b> Proceso de modelación de parámetros.</a></li>
<li class="chapter" data-level="3.4" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-verosimilitud"><i class="fa fa-check"></i><b>3.4</b> Función de verosimilitud</a></li>
<li class="chapter" data-level="3.5" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#familias-conjugadas"><i class="fa fa-check"></i><b>3.5</b> Familias conjugadas</a></li>
<li class="chapter" data-level="3.6" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#densidades-previas-impropias"><i class="fa fa-check"></i><b>3.6</b> Densidades previas impropias</a></li>
<li class="chapter" data-level="3.7" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#funciones-de-pérdida"><i class="fa fa-check"></i><b>3.7</b> Funciones de pérdida</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-pérdida-cuadrática"><i class="fa fa-check"></i><b>3.7.1</b> Función de pérdida cuadrática</a></li>
<li class="chapter" data-level="3.7.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-pérdida-absoluta"><i class="fa fa-check"></i><b>3.7.2</b> Función de pérdida absoluta</a></li>
<li class="chapter" data-level="3.7.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#otras-funciones-de-pérdida"><i class="fa fa-check"></i><b>3.7.3</b> Otras funciones de pérdida</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#efecto-de-muestras-grandes"><i class="fa fa-check"></i><b>3.8</b> Efecto de muestras grandes</a></li>
<li class="chapter" data-level="3.9" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#consistencia"><i class="fa fa-check"></i><b>3.9</b> Consistencia</a></li>
<li class="chapter" data-level="3.10" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#laboratorio"><i class="fa fa-check"></i><b>3.10</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-previa"><i class="fa fa-check"></i><b>3.10.1</b> Distribución previa</a></li>
<li class="chapter" data-level="3.10.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-conjunta"><i class="fa fa-check"></i><b>3.10.2</b> Distribución conjunta</a></li>
<li class="chapter" data-level="3.10.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-posterior"><i class="fa fa-check"></i><b>3.10.3</b> Distribución posterior</a></li>
<li class="chapter" data-level="3.10.4" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#agregando-nuevos-datos"><i class="fa fa-check"></i><b>3.10.4</b> Agregando nuevos datos</a></li>
<li class="chapter" data-level="3.10.5" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#familias-conjugadas-normales"><i class="fa fa-check"></i><b>3.10.5</b> Familias conjugadas normales</a></li>
<li class="chapter" data-level="3.10.6" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#funciones-de-pérdida-1"><i class="fa fa-check"></i><b>3.10.6</b> Funciones de pérdida</a></li>
<li class="chapter" data-level="3.10.7" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#caso-concreto"><i class="fa fa-check"></i><b>3.10.7</b> Caso concreto</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html"><i class="fa fa-check"></i><b>4</b> Estimación por máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="4.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#propiedades-del-mle"><i class="fa fa-check"></i><b>4.1</b> Propiedades del MLE</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#propiedad-de-invarianza"><i class="fa fa-check"></i><b>4.1.1</b> Propiedad de invarianza</a></li>
<li class="chapter" data-level="4.1.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#consistencia-1"><i class="fa fa-check"></i><b>4.1.2</b> Consistencia</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#cálculo-numérico"><i class="fa fa-check"></i><b>4.2</b> Cálculo numérico</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#método-de-los-momentos"><i class="fa fa-check"></i><b>4.2.1</b> Método de los momentos</a></li>
<li class="chapter" data-level="4.2.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#método-delta"><i class="fa fa-check"></i><b>4.2.2</b> Método Delta</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#laboratorio-1"><i class="fa fa-check"></i><b>4.3</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html"><i class="fa fa-check"></i><b>5</b> Estadísticos Suficientes y Criterio de Factorización</a>
<ul>
<li class="chapter" data-level="5.1" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadísticos-suficientes"><i class="fa fa-check"></i><b>5.1</b> Estadísticos suficientes</a></li>
<li class="chapter" data-level="5.2" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#teorema-de-factorización-de-fisher"><i class="fa fa-check"></i><b>5.2</b> Teorema de Factorización de Fisher</a></li>
<li class="chapter" data-level="5.3" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadístico-suficiente-multivariado."><i class="fa fa-check"></i><b>5.3</b> Estadístico suficiente multivariado.</a></li>
<li class="chapter" data-level="5.4" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadísticos-minimales"><i class="fa fa-check"></i><b>5.4</b> Estadísticos minimales</a></li>
<li class="chapter" data-level="5.5" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#mejorando-estimadores"><i class="fa fa-check"></i><b>5.5</b> Mejorando estimadores</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html"><i class="fa fa-check"></i><b>6</b> Distribución muestral de un estadístico</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-muestral"><i class="fa fa-check"></i><b>6.1</b> Distribución muestral</a></li>
<li class="chapter" data-level="6.2" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-chi2"><i class="fa fa-check"></i><b>6.2</b> Distribución <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="6.3" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-t"><i class="fa fa-check"></i><b>6.3</b> Distribución <span class="math inline">\(t\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>7</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="7.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-la-media-de-una-distribución-normal"><i class="fa fa-check"></i><b>7.1</b> Intervalos de confianza para la media de una distribución normal</a></li>
<li class="chapter" data-level="7.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#caso-normal."><i class="fa fa-check"></i><b>7.2</b> Caso normal.</a></li>
<li class="chapter" data-level="7.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-abiertos"><i class="fa fa-check"></i><b>7.3</b> Intervalos de confianza abiertos</a></li>
<li class="chapter" data-level="7.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-en-otros-casos"><i class="fa fa-check"></i><b>7.4</b> Intervalos de confianza en otros casos</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-aproximados."><i class="fa fa-check"></i><b>7.4.1</b> Intervalos de confianza aproximados.</a></li>
<li class="chapter" data-level="7.4.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#transformaciones-estabilizadoras-de-la-varianza"><i class="fa fa-check"></i><b>7.4.2</b> Transformaciones estabilizadoras de la varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html"><i class="fa fa-check"></i><b>8</b> Estimación Bayesiana bajo normalidad</a>
<ul>
<li class="chapter" data-level="8.1" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#precisión-de-una-distribución-normal"><i class="fa fa-check"></i><b>8.1</b> Precisión de una distribución normal</a></li>
<li class="chapter" data-level="8.2" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#distribución-marginal-de-mu"><i class="fa fa-check"></i><b>8.2</b> Distribución marginal de <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="8.3" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#intervalos-de-credibilidad."><i class="fa fa-check"></i><b>8.3</b> Intervalos de credibilidad.</a></li>
<li class="chapter" data-level="8.4" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#efecto-de-previas-no-informativas-opcional"><i class="fa fa-check"></i><b>8.4</b> Efecto de previas no informativas (Opcional)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html"><i class="fa fa-check"></i><b>9</b> Estimación insesgada</a>
<ul>
<li class="chapter" data-level="9.1" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimadores-insesgados"><i class="fa fa-check"></i><b>9.1</b> Estimadores insesgados</a></li>
<li class="chapter" data-level="9.2" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimador-insesgado-de-la-varianza"><i class="fa fa-check"></i><b>9.2</b> Estimador insesgado de la varianza</a></li>
<li class="chapter" data-level="9.3" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#información-de-fisher"><i class="fa fa-check"></i><b>9.3</b> Información de Fisher</a></li>
<li class="chapter" data-level="9.4" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#desigualdad-de-cramer-rao"><i class="fa fa-check"></i><b>9.4</b> Desigualdad de Cramer-Rao</a></li>
<li class="chapter" data-level="9.5" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimadores-eficientes"><i class="fa fa-check"></i><b>9.5</b> Estimadores eficientes</a></li>
<li class="chapter" data-level="9.6" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#comportamiento-asintótico-del-mle"><i class="fa fa-check"></i><b>9.6</b> Comportamiento asintótico del MLE</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>10</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-hipótesis-1"><i class="fa fa-check"></i><b>10.1</b> Pruebas de hipótesis</a></li>
<li class="chapter" data-level="10.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#regiones-críticas-y-estadísticas-de-prueba"><i class="fa fa-check"></i><b>10.2</b> Regiones críticas y estadísticas de prueba</a></li>
<li class="chapter" data-level="10.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#función-de-potencia-y-tipos-de-error"><i class="fa fa-check"></i><b>10.3</b> Función de potencia y tipos de error</a></li>
<li class="chapter" data-level="10.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#valor-p"><i class="fa fa-check"></i><b>10.4</b> Valor <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="10.5" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#dualidad-entre-pruebas-de-hipótesis-y-regiones-de-confianza"><i class="fa fa-check"></i><b>10.5</b> Dualidad entre pruebas de hipótesis y regiones de confianza</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#dualidad-en-pruebas-unilaterales"><i class="fa fa-check"></i><b>10.5.1</b> Dualidad en pruebas unilaterales</a></li>
<li class="chapter" data-level="10.5.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-cociente-de-verosimilitud-lrt"><i class="fa fa-check"></i><b>10.5.2</b> Pruebas de cociente de verosimilitud (LRT)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html"><i class="fa fa-check"></i><b>11</b> Pruebas con hipótesis simples</a>
<ul>
<li class="chapter" data-level="11.1" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#hipótesis-simples"><i class="fa fa-check"></i><b>11.1</b> Hipótesis simples</a></li>
<li class="chapter" data-level="11.2" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#criterio-de-neyman-pearson"><i class="fa fa-check"></i><b>11.2</b> Criterio de Neyman-Pearson</a></li>
<li class="chapter" data-level="11.3" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#pruebas-insesgadas"><i class="fa fa-check"></i><b>11.3</b> Pruebas insesgadas</a></li>
<li class="chapter" data-level="11.4" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#prueba-t"><i class="fa fa-check"></i><b>11.4</b> Prueba <span class="math inline">\(t\)</span></a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#propiedades-de-las-pruebas-t"><i class="fa fa-check"></i><b>11.4.1</b> Propiedades de las pruebas <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="11.4.2" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#prueba-t-pareada"><i class="fa fa-check"></i><b>11.4.2</b> Prueba <span class="math inline">\(t\)</span> pareada</a></li>
<li class="chapter" data-level="11.4.3" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#pruebas-t-de-dos-colas"><i class="fa fa-check"></i><b>11.4.3</b> Pruebas <span class="math inline">\(t\)</span> de dos colas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html"><i class="fa fa-check"></i><b>12</b> Prueba de comparación de medias en 2 poblaciones</a>
<ul>
<li class="chapter" data-level="12.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#comparación-de-medias-normales"><i class="fa fa-check"></i><b>12.1</b> Comparación de medias normales</a></li>
<li class="chapter" data-level="12.2" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-t-de-dos-muestras"><i class="fa fa-check"></i><b>12.2</b> Prueba <span class="math inline">\(t\)</span> de dos muestras</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-de-2-colas"><i class="fa fa-check"></i><b>12.2.1</b> Prueba de 2 colas</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-f"><i class="fa fa-check"></i><b>12.3</b> Prueba <span class="math inline">\(F\)</span></a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-de-2-colas-prueba-de-homocedasticidad"><i class="fa fa-check"></i><b>12.3.1</b> Prueba de 2 colas (prueba de homocedasticidad)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html"><i class="fa fa-check"></i><b>13</b> Bondad de ajuste</a>
<ul>
<li class="chapter" data-level="13.1" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html#prueba-chi2"><i class="fa fa-check"></i><b>13.1</b> Prueba <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="13.2" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html#pruebas-chi2-con-hipótesis-parametrizadas"><i class="fa fa-check"></i><b>13.2</b> Pruebas <span class="math inline">\(\chi^2\)</span> con hipótesis parametrizadas</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html"><i class="fa fa-check"></i><b>14</b> Tablas de contingencia</a>
<ul>
<li class="chapter" data-level="14.1" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#prueba-de-independencia"><i class="fa fa-check"></i><b>14.1</b> Prueba de independencia</a></li>
<li class="chapter" data-level="14.2" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#prueba-de-homogeneidad"><i class="fa fa-check"></i><b>14.2</b> Prueba de homogeneidad</a></li>
<li class="chapter" data-level="14.3" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#similitudes-entre-las-pruebas-de-independecia-y-homogeneidad"><i class="fa fa-check"></i><b>14.3</b> Similitudes entre las pruebas de independecia y homogeneidad</a></li>
<li class="chapter" data-level="14.4" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#comparación-de-dos-o-más-proporciones"><i class="fa fa-check"></i><b>14.4</b> Comparación de dos o más proporciones</a></li>
<li class="chapter" data-level="14.5" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#paradoja-de-simpson"><i class="fa fa-check"></i><b>14.5</b> Paradoja de Simpson</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#cómo-evitamos-esta-paradoja"><i class="fa fa-check"></i><b>14.5.1</b> ¿Cómo evitamos esta paradoja?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="pruebas-de-kolmogorov-smirnov.html"><a href="pruebas-de-kolmogorov-smirnov.html"><i class="fa fa-check"></i><b>15</b> Pruebas de Kolmogorov-Smirnov</a>
<ul>
<li class="chapter" data-level="15.1" data-path="pruebas-de-kolmogorov-smirnov.html"><a href="pruebas-de-kolmogorov-smirnov.html#prueba-de-kolmogorov-smirnov-para-una-muestra"><i class="fa fa-check"></i><b>15.1</b> Prueba de Kolmogorov-Smirnov para una muestra</a></li>
<li class="chapter" data-level="15.2" data-path="pruebas-de-kolmogorov-smirnov.html"><a href="pruebas-de-kolmogorov-smirnov.html#prueba-de-2-muestras"><i class="fa fa-check"></i><b>15.2</b> Prueba de 2 muestras</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html"><a href="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html"><i class="fa fa-check"></i><b>16</b> Pruebas no-paramétricas: pruebas de signo y rango</a>
<ul>
<li class="chapter" data-level="16.1" data-path="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html"><a href="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html#prueba-de-signo"><i class="fa fa-check"></i><b>16.1</b> Prueba de signo</a></li>
<li class="chapter" data-level="16.2" data-path="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html"><a href="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html#prueba-de-wilconxon-mann-whitney"><i class="fa fa-check"></i><b>16.2</b> Prueba de Wilconxon-Mann-Whitney</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html"><i class="fa fa-check"></i><b>17</b> Ejercicios varios</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html#capítulo-8"><i class="fa fa-check"></i><b>17.1</b> Capítulo 8</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html#section"><i class="fa fa-check"></i><b>17.1.1</b> 8.4.6</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas Curso de Estadística (Parte I)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bondad-de-ajuste" class="section level1" number="13">
<h1><span class="header-section-number">Capítulo 13</span> Bondad de ajuste</h1>
<p>En los ejemplos que hemos visto siempre hemos necesitado una distribución de
referencia que nos permita calcular los cuantiles correspondientes. Sin embargo,
es posible que ese supuesto no se cumpla, o que la distribución no sea normal
por ejemplo. En estos casos primero se debe de considerar una prueba de
hipótesis para revisar las condiciones de nuestros datos. Una familia de
problemas no paramétricos surgen a partir de esta observación.</p>
<!-- **Ejemplo**. 23 dispositivos mecánicos con sus tiempos de fallo (log-tiempo). -->
<!-- ¿Los datos son normales? La hipótesis nula es la normalidad, lo que representa -->
<!-- un problema no paramétrico. -->
<div id="prueba-chi2" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Prueba <span class="math inline">\(\chi^2\)</span></h2>
<p>Suponga que se tienen <strong>datos categóricos</strong> los cuales el rango de la variable
asume un número finito de categorías o estados</p>
<p><strong>Ejemplo:</strong> Por ejemplo suponga que tienen la variable de tipo de sangre en la población, entonces</p>
<table>
<thead>
<tr class="header">
<th>Categoría</th>
<th>Tipo de sangre</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>A</td>
</tr>
<tr class="even">
<td>2</td>
<td>B</td>
</tr>
<tr class="odd">
<td>3</td>
<td>AB</td>
</tr>
<tr class="even">
<td>4</td>
<td>O</td>
</tr>
</tbody>
</table>
<p>Suponga que tenemos <span class="math inline">\(k\)</span> categorías,</p>
<p><span class="math display">\[p_i = \mathbb P[\text{Categoría }i],\;i=1,\dotsc,k\]</span></p>
<p>y <span class="math inline">\(\sum_{i=1}^kp_i = 1\)</span>. Sea <span class="math inline">\(p_1^0,\dotsc,p_k^0\)</span>
probabilidades propuestas, <span class="math inline">\(\sum_{i=1}^kp_i^0\)</span>.</p>
<p>Suponga
<span class="math display">\[ H_0: p_i = p_i^0\text{ para } i=1,\dots,k\]</span>
<span class="math display">\[ H_1: p_i \ne p_i^0\text{ para al menos un }i\]</span></p>
<p><strong>Ejemplo:</strong> Siguiendo con el ejemplo, suponga que se quiere hacer la siguiente hipótesis de la población</p>
<table>
<thead>
<tr class="header">
<th>Categoría</th>
<th>Tipo de sangre</th>
<th>Hipótesis (<span class="math inline">\(p_i ^{0}\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>A</td>
<td>1/3</td>
</tr>
<tr class="even">
<td>2</td>
<td>B</td>
<td>1/8</td>
</tr>
<tr class="odd">
<td>3</td>
<td>AB</td>
<td>1/24</td>
</tr>
<tr class="even">
<td>4</td>
<td>O</td>
<td>1/2</td>
</tr>
</tbody>
</table>
<p>Suponga una muestra de <span class="math inline">\(n\)</span> elementos. <span class="math inline">\(N_i\)</span> el número de elementos en la categoría <span class="math inline">\(i\)</span>, <span class="math inline">\(\sum _{i=1}^kN_i = n\)</span>. Note que
<span class="math display">\[(N_1,\dots,N_k)\sim\text{Multinomial}(p_1, \dots, p_k)\]</span></p>
<p><strong>Nota:</strong> Una distribución multinomial tiene la siguiente forma:</p>
<p><span class="math display">\[\begin{align*}
\operatorname{Pr}\left(X_{1}=x_{1}, \ldots, X_{k}=x_{k}\right) = 
\left\{\begin{array}{rlr}
\binom {n} {x_{1}, \ldots, x_{k}} p_{1}^{x_{1}} \cdots p_{k}^{x_{k}} &amp; \text { if } x_{1}+\cdots+x_{k}=n \\
0 &amp; \text { otherwise. }
\end{array}\right.
\end{align*}\]</span></p>
<p>donde</p>
<p><span class="math display">\[\begin{equation*}
\binom{n}{x_{1}, \ldots, x_{k}}
=\frac{n !}{x_{1} ! x_{2} ! \cdots x_{k} !}
\end{equation*}\]</span></p>
<p>El número esperado de elementos en la celda <span class="math inline">\(i\)</span> es <span class="math inline">\(n\cdot p_i^0\)</span>. Si <span class="math inline">\(N_i -np_i^0\)</span> es cercano a 0 para todo <span class="math inline">\(i\)</span>, es indicador de que <span class="math inline">\(H_0\)</span> es cierto.</p>
<p>El <strong>estadístico <span class="math inline">\(\chi^2\)</span></strong> se define como</p>
<p><span class="math display">\[Q = \sum_{i=1}^k\dfrac{(N_i-np_i^0)^2}{np_i^0}.\]</span></p>
<p>En 1900, Karl Pearson probó que cuando <span class="math inline">\(n\)</span> es grande y <span class="math inline">\(k\)</span> es “relativamente”
pequeño con respecto a <span class="math inline">\(n\)</span>,</p>
<p><span class="math display">\[Q \xrightarrow[H_0]{}\chi^2_{k-1}.\]</span></p>
<p>En la prueba <span class="math inline">\(\chi^2\)</span>, <span class="math inline">\(\delta\)</span>: Rechazo <span class="math inline">\(H_0\)</span> si <span class="math inline">\(Q\geq c\)</span>. Dado un nivel de significancia <span class="math inline">\(\alpha_0\)</span>,
<span class="math display">\[\mathbb P_{H_0}[Q\geq c]\le \alpha_0\implies c = F^{-1}_{\chi^2_{k-1}}(1-\alpha_0)\]</span></p>
<p><strong>Nota:</strong> El estadístico <span class="math inline">\(Q\)</span> se puede interpretar de la forma</p>
<p><span class="math display">\[Q = \sum_{i=1}^k\dfrac{(\text{observado}_{i} - \text{esperado}_{i})^2}{\text{esperado}_{i}}.\]</span></p>
<p><strong>Reglas empíricas</strong></p>
<ol style="list-style-type: decimal">
<li><p>La aproximación <span class="math inline">\((Q\sim\chi^{k-1})\)</span> funciona muy bien si <span class="math inline">\(np_i^0\geq 5\)</span>.</p></li>
<li><p>La aproximación es buena si <span class="math inline">\(np_i^0\ge 1.5\)</span>, <span class="math inline">\(i=1,\dots,k\)</span>.</p></li>
</ol>
<p><strong>Ejemplo</strong>: Continuando con el ejemplo se observan 6004 personas de raza blanca en California y se obtiene este resultado</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(\text{Grupo}\)</span></th>
<th><span class="math inline">\(\text{Observado}\)</span> (<span class="math inline">\(n_i\)</span>)</th>
<th><span class="math inline">\(\text{Teórico}\)</span> (<span class="math inline">\(p_i ^{0}\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\text A\)</span></td>
<td><span class="math inline">\(2162\)</span></td>
<td><span class="math inline">\(1/3\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\text B\)</span></td>
<td><span class="math inline">\(738\)</span></td>
<td><span class="math inline">\(1/8\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\text {AB}\)</span></td>
<td><span class="math inline">\(228\)</span></td>
<td><span class="math inline">\(1/24\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\text O\)</span></td>
<td><span class="math inline">\(2876\)</span></td>
<td><span class="math inline">\(1/2\)</span></td>
</tr>
</tbody>
</table>
<p>Queremos probar <span class="math inline">\(H_0: p_i = p_i^0\)</span>, <span class="math inline">\(i=1,2,3,4\)</span>.</p>
<ul>
<li><p><span class="math inline">\(np_1^0 = 6004\cdot1/3 = 2001.3\)</span>.</p></li>
<li><p><span class="math inline">\(np_2^0 = 6004\cdot1/8 = 750.5\)</span>.</p></li>
<li><p><span class="math inline">\(np_3^0 = 6004\cdot1/24 = 250.2\)</span>.</p></li>
<li><p><span class="math inline">\(np_4^0 = 6004\cdot1/2 = 3002\)</span>.</p></li>
</ul>
<p><span class="math display">\[Q = \dfrac{(2162-2001.3)^2}{2001.3} + \dfrac{(738-750.5)^2}{750.5} + \dfrac{(228-250.2)^2}{250.2} + \dfrac{(2876-3002)^2}{3002} = 20.37.\]</span></p>
<p>El valor-<em>p</em> es <span class="math inline">\(F_{\chi^2_{3}}(20.37) = 1.42\times 10^{-4}\)</span>.</p>
<p>En R el test se puede hacer con la función <code>chisq.test</code>:</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="bondad-de-ajuste.html#cb328-1"></a>observado &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2162</span>, <span class="dv">738</span>, <span class="dv">228</span>, <span class="dv">2876</span>)</span>
<span id="cb328-2"><a href="bondad-de-ajuste.html#cb328-2"></a></span>
<span id="cb328-3"><a href="bondad-de-ajuste.html#cb328-3"></a>probabilidad_hipotetica &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">3</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">8</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">24</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)</span>
<span id="cb328-4"><a href="bondad-de-ajuste.html#cb328-4"></a></span>
<span id="cb328-5"><a href="bondad-de-ajuste.html#cb328-5"></a><span class="kw">chisq.test</span>(<span class="dt">x =</span> observado, <span class="dt">p =</span> probabilidad_hipotetica)</span></code></pre></div>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  observado
## X-squared = 20.359, df = 3, p-value = 0.000143</code></pre>
<p>Rechazamos la hipótesis de que las probabilidades teóricas de tipo de sangre son
igual al valor hipotético.</p>
<p><strong>Ejemplo</strong>. Sean <span class="math inline">\(0&lt;X_i&lt;1\)</span>, <span class="math inline">\(i=1,2,\dots,100\)</span>. <span class="math inline">\(X_i~f\)</span>, <span class="math inline">\(f\)</span> una densidad continua.</p>
<p><span class="math display">\[H_0: f=\text{Unif}(0,1) \text{ vs } H_1: f \ne\text{Unif}(0,1). \]</span></p>
<p>Se definen 20 niveles, que corresponden a intervalos de [0,1]. Una observación
<span class="math inline">\(X_j\)</span> está en el nivel <span class="math inline">\(i\)</span> si</p>
<p><span class="math display">\[\dfrac{i-1}{20}\leq X_j &lt;\dfrac{i}{20}\]</span>.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(\text{Nivel}\)</span></th>
<th><span class="math inline">\(1\)</span></th>
<th><span class="math inline">\(2\)</span></th>
<th><span class="math inline">\(\cdots\)</span></th>
<th><span class="math inline">\(20\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\text{Frecuencia}\)</span></td>
<td><span class="math inline">\(N_1\)</span></td>
<td><span class="math inline">\(N_2\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(N_{20}\)</span></td>
</tr>
</tbody>
</table>
<p>donde <span class="math inline">\(N_i\)</span> es el número de observaciones que están en el intervalo <span class="math inline">\(i\)</span>.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(i\)</span></th>
<th><span class="math inline">\(X_i\)</span></th>
<th><span class="math inline">\(\text{Grupo}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(X_1\)</span></td>
<td><span class="math inline">\(2\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(X_2\)</span></td>
<td><span class="math inline">\(4\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(X_3\)</span></td>
<td><span class="math inline">\(17\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(100\)</span></td>
<td><span class="math inline">\(X_{100}\)</span></td>
<td><span class="math inline">\(20\)</span></td>
</tr>
</tbody>
</table>
<p>Las hipótesis anteriores son equivalentes a
<span class="math display">\[H_0: p_i = \dfrac{1}{20}, \;i=1,\dots,20.\]</span></p>
<p><span class="math inline">\(np_i^0 = 100\cdot\dfrac 1{20} = 5,\;i = 1,\dots,20\)</span>.</p>
<p>Entonces
<span class="math display">\[Q = \sum_{i=1}^{20}\dfrac{(N_i-5)^2}{5}.\]</span></p>
<p>Rechazamos la hipótesis <span class="math inline">\(f = \text{Unif}(0,1)\)</span> si <span class="math inline">\(Q&gt;\chi^2_{19}(1-\alpha_0)\)</span>.</p>
<p><strong>Nota:</strong> Este método funciona para cualquier tipo de distribución. El siguiente
procedimiento se debe seguir para estos casos</p>
<ol style="list-style-type: lower-roman">
<li><p>Particione en <span class="math inline">\(k\)</span> subintervalos disjuntos la recta real o cualquier intervalo
en el que esté contenidos sus datos de modo que este tenga probalidad 1. Es
decir, todos sus datos deben estar contenidos en este intervalo.</p></li>
<li><p>Determine las probabilidades <span class="math inline">\(p_i ^{0}\)</span> hipotéticas que se asignará cada
subintervalo. El valor teórico para cada subintervalo será <span class="math inline">\(n p_i ^{0}\)</span></p></li>
<li><p>Cuente las observaciones que caen en cada subintervalo. Llame este valor <span class="math inline">\(N_i\)</span></p></li>
<li><p>Calcule <span class="math inline">\(Q\)</span> según el procedimiento anterior y tome una decisión con respecto
a la hipótesis nula. La hipótesis nula deberá tener una distribución <span class="math inline">\(\chi ^{2}\)</span>
con <span class="math inline">\(k-1\)</span> grados de libertad.</p></li>
</ol>
<p><strong>Ejemplo</strong>. Supongamos que tenemos 23 datos de unas partes mecánicas para automóvil. Se registró el sus tiempos de vida útil.</p>
<p>Trabajemos con el ejemplo de log-tiempo de vida de los dispositivos.</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="bondad-de-ajuste.html#cb330-1"></a>x &lt;-<span class="st"> </span><span class="kw">c</span>(</span>
<span id="cb330-2"><a href="bondad-de-ajuste.html#cb330-2"></a>  <span class="fl">17.88</span>, <span class="fl">28.92</span>, <span class="dv">33</span>, <span class="fl">41.52</span>, <span class="fl">42.12</span>, <span class="fl">45.6</span>, <span class="fl">48.8</span>, <span class="fl">51.84</span>, <span class="fl">51.96</span>, <span class="fl">54.12</span>, <span class="fl">55.56</span>,</span>
<span id="cb330-3"><a href="bondad-de-ajuste.html#cb330-3"></a>  <span class="fl">67.8</span>, <span class="fl">68.44</span>, <span class="fl">68.64</span>, <span class="fl">68.88</span>, <span class="fl">84.12</span>, <span class="fl">93.12</span>, <span class="fl">98.64</span>, <span class="fl">105.12</span>, <span class="fl">105.84</span>, <span class="fl">127.92</span>,</span>
<span id="cb330-4"><a href="bondad-de-ajuste.html#cb330-4"></a>  <span class="fl">128.04</span>, <span class="fl">173.4</span></span>
<span id="cb330-5"><a href="bondad-de-ajuste.html#cb330-5"></a>)</span>
<span id="cb330-6"><a href="bondad-de-ajuste.html#cb330-6"></a></span>
<span id="cb330-7"><a href="bondad-de-ajuste.html#cb330-7"></a>log_x &lt;-<span class="st"> </span><span class="kw">log</span>(x)</span></code></pre></div>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="bondad-de-ajuste.html#cb331-1"></a><span class="kw">hist</span>(x)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/13-bondad-de-ajuste-3-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="bondad-de-ajuste.html#cb332-1"></a><span class="kw">hist</span>(log_x)</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/13-bondad-de-ajuste-3-2.svg" width="100%" style="display: block; margin: auto;" /></p>
<p>Suponga que se quiere hacer la prueba de hipótesis</p>
<p><span class="math display">\[H_0: f = N(\log(50),0.25) \quad vs \quad H_1: f \neq N(\log(50),0.25)\]</span></p>
<p>Seleccione <span class="math inline">\(k\)</span> tal que</p>
<p><span class="math display">\[
p_i^0 = \mathbb P[\text{log-tiempo perteneza al }i\text{-ésimo intervalo}]\geq \dfrac 5{23}\approx \dfrac 14.
\]</span></p>
<p>Podemos tomar <span class="math inline">\(k = 4\)</span> grupos (intervalos regulares)</p>
<ol style="list-style-type: decimal">
<li><p>Grupo 1: <span class="math inline">\((F^{-1}_{H_0}(0),F^{-1}_{H_0}(0.25)] = (-\infty,3.575]\)</span>.</p></li>
<li><p>Grupo 2: <span class="math inline">\((F^{-1}_{H_0}(0.25),F^{-1}_{H_0}(0.5)] = (3.575,3.912]\)</span>.</p></li>
<li><p>Grupo 3: <span class="math inline">\((F^{-1}_{H_0}(0.5),F^{-1}_{H_0}(0.75)]=(3.912,4.249]\)</span>.</p></li>
<li><p>Grupo 4: <span class="math inline">\((F^{-1}_{H_0}(0.75),F^{-1}_{H_0}(1))=(4.249,+\infty)\)</span>.</p></li>
</ol>
<p>Entonces solo para efectos de construir la partición</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="bondad-de-ajuste.html#cb333-1"></a>cortes &lt;-<span class="st"> </span><span class="kw">qnorm</span>(</span>
<span id="cb333-2"><a href="bondad-de-ajuste.html#cb333-2"></a>  <span class="dt">p =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">3</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">1</span>),</span>
<span id="cb333-3"><a href="bondad-de-ajuste.html#cb333-3"></a>  <span class="dt">mean =</span> <span class="kw">log</span>(<span class="dv">50</span>),</span>
<span id="cb333-4"><a href="bondad-de-ajuste.html#cb333-4"></a>  <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="fl">0.25</span>)</span>
<span id="cb333-5"><a href="bondad-de-ajuste.html#cb333-5"></a>)</span>
<span id="cb333-6"><a href="bondad-de-ajuste.html#cb333-6"></a></span>
<span id="cb333-7"><a href="bondad-de-ajuste.html#cb333-7"></a>(intervalos &lt;-<span class="st"> </span><span class="kw">cut</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="dt">breaks =</span> cortes))</span></code></pre></div>
<pre><code>## [1] (-Inf,3.57] (4.25, Inf]
## Levels: (-Inf,3.57] (3.57,3.91] (3.91,4.25] (4.25, Inf]</code></pre>
<div class="sourceCode" id="cb335"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb335-1"><a href="bondad-de-ajuste.html#cb335-1"></a>(conteos &lt;-<span class="st"> </span><span class="kw">cut</span>(log_x, <span class="dt">breaks =</span> cortes))</span></code></pre></div>
<pre><code>##  [1] (-Inf,3.57] (-Inf,3.57] (-Inf,3.57] (3.57,3.91] (3.57,3.91] (3.57,3.91]
##  [7] (3.57,3.91] (3.91,4.25] (3.91,4.25] (3.91,4.25] (3.91,4.25] (3.91,4.25]
## [13] (3.91,4.25] (3.91,4.25] (3.91,4.25] (4.25, Inf] (4.25, Inf] (4.25, Inf]
## [19] (4.25, Inf] (4.25, Inf] (4.25, Inf] (4.25, Inf] (4.25, Inf]
## Levels: (-Inf,3.57] (3.57,3.91] (3.91,4.25] (4.25, Inf]</code></pre>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="bondad-de-ajuste.html#cb337-1"></a><span class="kw">summary</span>(conteos)</span></code></pre></div>
<pre><code>## (-Inf,3.57] (3.57,3.91] (3.91,4.25] (4.25, Inf] 
##           3           4           8           8</code></pre>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(G_1\)</span></th>
<th><span class="math inline">\(G_2\)</span></th>
<th><span class="math inline">\(G_3\)</span></th>
<th><span class="math inline">\(G_4\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(4\)</span></td>
<td><span class="math inline">\(8\)</span></td>
<td><span class="math inline">\(8\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math display">\[Q = \dfrac{(3-23\cdot1/4)^2}{23\cdot 1/4} +  \dfrac{(4-23\cdot1/4)^2}{23\cdot 1/4}+\dfrac{(8-23\cdot1/4)^2}{23\cdot 1/4} + \dfrac{(8-23\cdot1/4)^2}{23\cdot 1/4}= 3.609.\]</span></p>
<p>El valor-<span class="math inline">\(p\)</span> corresponde a <span class="math inline">\(F_{\chi^2_3}(3.609) = 0.307\)</span>.</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="bondad-de-ajuste.html#cb339-1"></a>conteos &lt;-<span class="st"> </span><span class="kw">summary</span>(conteos)</span>
<span id="cb339-2"><a href="bondad-de-ajuste.html#cb339-2"></a></span>
<span id="cb339-3"><a href="bondad-de-ajuste.html#cb339-3"></a><span class="kw">chisq.test</span>(conteos)</span></code></pre></div>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  conteos
## X-squared = 3.6087, df = 3, p-value = 0.3069</code></pre>
<p><strong>Nota:</strong> La función <code>chisq.test</code> si no se llama con ninguna hipótesis nula <code>p</code>,
esta asume que <span class="math inline">\(p = 1/n\)</span> para cada categoría. En este caso como son 4
categorías sería <span class="math inline">\(1/4\)</span>.</p>
<p>Con un nivel de 30%, no se rechaza la hipótesis de normalidad bajo esa escogencia
de parámetros.</p>
<p><strong>Nota:</strong> Otra escogencia de paramétros podría aceptar la hipótesis nula.</p>
</div>
<div id="pruebas-chi2-con-hipótesis-parametrizadas" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Pruebas <span class="math inline">\(\chi^2\)</span> con hipótesis parametrizadas</h2>
<p><strong>Ejemplo.</strong> En el caso anterior, probamos que la distribución Normal con media <span class="math inline">\(\log(50) = 3.912023\)</span> y desviación estándar <span class="math inline">\(0.25\)</span> no funcionabapara nuestros datos.</p>
<p>La pregunta es entonces, ¿Cuáles serían los parámetros correctos? ¿Los datos
pertenecen a una familia normal?</p>
<p>En esta sección veremos una técnica para lidiar con este problema.</p>
<p>Escriba cada <span class="math inline">\(p_i\)</span> <span class="math inline">\((i=1,\dots,k)\)</span> como</p>
<p><span class="math display">\[p_i = \pi_i(\theta),\quad \theta = (\theta_1,\dots,\theta_s)\]</span></p>
<p>Es decir, cada probabilidad es igual a una función particular con respecto a
algunos paramétros <span class="math inline">\(\mathbf{\theta}\)</span>.</p>
<p>Asuma que <span class="math inline">\(s&lt;k-1\)</span>. Las entradas de <span class="math inline">\(\theta\)</span> no se pueden escribir como función
de ellas mismas. Además <span class="math inline">\(\sum \pi_i(\theta) = 1\)</span>.</p>
<p><span class="math display">\[H_0: p_i = \pi_i(\theta)\text{ para algún parámetro }\theta\in
\Omega,\;i=1,\dots,k\]</span></p>
<p><span class="math display">\[H_1: \text{lo anterior no es cierto}\]</span></p>
<p>El estadístico es</p>
<p><span class="math display">\[Q = \sum_{i=1}^k\dfrac{[N_i-n\pi_i(\hat\theta)]^2}{n\pi_i(\hat\theta)}\]</span></p>
<p>con <span class="math inline">\(\hat\theta\)</span> el MLE de <span class="math inline">\(\theta\)</span> usando la distribución de <span class="math inline">\((N_1,\dots,N_k)\)</span>.</p>
<p><strong>Teorema</strong>. Bajo <span class="math inline">\(H_0\)</span>, conforme <span class="math inline">\(n\to \infty\)</span>, <span class="math inline">\(Q\to \chi^2_{k-1-s}\)</span>.</p>
<p><strong>Ejemplo</strong>. Suponga que se tienen 3 grupos y defina una parámetro <span class="math inline">\(0&lt;\theta&lt;1\)</span>.
El análisista hace el siguiente supuesto:</p>
<p><span class="math display">\[\begin{align*}
p_1 &amp;= \theta^2=\pi_1(\theta)  , \\
p_2 &amp;= 2\theta(1-\theta)=\pi_2(\theta),\\
p_3 &amp;= (1-\theta)^2=\pi_3(\theta).
\end{align*}\]</span></p>
<p>Se observa que <span class="math inline">\(p_1+p_2+p_3 = \theta^2 + 2\theta (1-\theta +(1-\theta)^2 =[\theta+(1-\theta)]^2 = 1\)</span>.</p>
<p><span class="math inline">\(s = 1\)</span>, <span class="math inline">\(\Omega = [0,1]\)</span>.</p>
<p>Como la distribución de
<span class="math inline">\((N_1,\dots,N_k)\underset{H_0}{\sim} \text{Multinomial}(n,p_1,\dots,p_k)\)</span>, se
obtiene la verosimilitud</p>
<p><span class="math display">\[L (\theta|N_1,\dots,N_k) = {n \choose {N_1\cdots N_k}}(\pi_1(\theta))^{N_1}\cdots(\pi_k(\theta))^{N_k}\]</span></p>
<p><span class="math display">\[\ell = \log (L) \propto N_1\ln\pi_1(\theta)+\cdots+N_k\ln\pi_k(\theta)\]</span></p>
<p>Retomando el ejemplo,</p>
<p><span class="math display">\[\begin{align*}
\ln L(\theta) &amp; \propto N_1\ln \theta^2 + N_2 \ln 2\theta(1-\theta) + N_3\ln (1-\theta)^2\\
&amp; = (2N_1+N_2)\ln \theta + (2N_3+N_2)\ln(1-\theta) + N_2\ln 2
\end{align*}\]</span></p>
<p><span class="math display">\[\dfrac{\partial \ln L(\theta)}{\partial\theta} = \dfrac{2N_1+N_2}{\theta}-\dfrac{2N_3+N_2}{1-\theta} = 0 \implies \hat\theta = \dfrac{2N_1+N_2}{2n}\]</span></p>
<p>Con esto se calcula <span class="math inline">\(\pi_1(\hat \theta)\)</span>,<span class="math inline">\(\pi_2(\hat \theta)\)</span>,<span class="math inline">\(\pi_3(\hat \theta)\)</span> y <span class="math inline">\(Q\)</span>.</p>
<p><strong>Ejemplo</strong> (Partes de automóvil). Sean <span class="math inline">\(X_1,\dots,X_n\sim f\)</span>, <span class="math inline">\(H_0: f = N(\mu,\sigma^2)\)</span> donde <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span> son desconocidos.</p>
<p>Vamos a construir las funciones <span class="math inline">\(\pi\)</span> tratando de ajustar los cuantiles que
habíamos definido antes con los valores teóricos de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>. Entonces,</p>
<p><span class="math display">\[\pi_i(\mu,\sigma^2) = \int_{a_i}^{b_i}(2\pi\sigma^2)^{-1/2}\exp\left(-\dfrac 1{2\sigma^2}(x-\mu)^2\right)dx = \Phi\left(\dfrac{b_i-\mu}{\sigma}\right)-\Phi\left(\dfrac{a_i-\mu}{\sigma}\right)\]</span></p>
<p>Asumiendo que la <em>i</em>-ésima partición es <span class="math inline">\((a_i,b_i)\)</span>, los 4 intervalos son</p>
<p><span class="math display">\[(-\infty,3.575],(3.575,3.912],(3.912,4.249], (4.249,+\infty).\]</span></p>
<p>La verosimilitud es</p>
<p><span class="math display">\[\ln L(\mu,\sigma^2) = N_1\ln \pi_1(\mu,\sigma^2)+\cdots+N_4\ln\pi_4(\mu,\sigma^2)\]</span></p>
<p>y se optimiza numéricamente.</p>
<div class="sourceCode" id="cb341"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb341-1"><a href="bondad-de-ajuste.html#cb341-1"></a>cortes &lt;-<span class="st"> </span><span class="kw">qnorm</span>(</span>
<span id="cb341-2"><a href="bondad-de-ajuste.html#cb341-2"></a>  <span class="dt">p =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">3</span> <span class="op">/</span><span class="st"> </span><span class="dv">4</span>, <span class="dv">1</span>),</span>
<span id="cb341-3"><a href="bondad-de-ajuste.html#cb341-3"></a>  <span class="dt">mean =</span> <span class="kw">log</span>(<span class="dv">50</span>),</span>
<span id="cb341-4"><a href="bondad-de-ajuste.html#cb341-4"></a>  <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="fl">0.25</span>)</span>
<span id="cb341-5"><a href="bondad-de-ajuste.html#cb341-5"></a>)</span>
<span id="cb341-6"><a href="bondad-de-ajuste.html#cb341-6"></a></span>
<span id="cb341-7"><a href="bondad-de-ajuste.html#cb341-7"></a>log_versomilitud &lt;-<span class="st"> </span><span class="cf">function</span>(par, cortes, log_x) {</span>
<span id="cb341-8"><a href="bondad-de-ajuste.html#cb341-8"></a>  G &lt;-<span class="st"> </span><span class="kw">length</span>(cortes)</span>
<span id="cb341-9"><a href="bondad-de-ajuste.html#cb341-9"></a>  mu &lt;-<span class="st"> </span>par[<span class="dv">1</span>]</span>
<span id="cb341-10"><a href="bondad-de-ajuste.html#cb341-10"></a>  sigma &lt;-<span class="st"> </span>par[<span class="dv">2</span>]</span>
<span id="cb341-11"><a href="bondad-de-ajuste.html#cb341-11"></a></span>
<span id="cb341-12"><a href="bondad-de-ajuste.html#cb341-12"></a>  pi &lt;-<span class="st"> </span><span class="kw">numeric</span>()</span>
<span id="cb341-13"><a href="bondad-de-ajuste.html#cb341-13"></a>  <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>(G <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) {</span>
<span id="cb341-14"><a href="bondad-de-ajuste.html#cb341-14"></a>    pi[k] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(<span class="dt">q =</span> cortes[k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>], <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma) <span class="op">-</span></span>
<span id="cb341-15"><a href="bondad-de-ajuste.html#cb341-15"></a><span class="st">      </span><span class="kw">pnorm</span>(<span class="dt">q =</span> cortes[k], <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)</span>
<span id="cb341-16"><a href="bondad-de-ajuste.html#cb341-16"></a>  }</span>
<span id="cb341-17"><a href="bondad-de-ajuste.html#cb341-17"></a></span>
<span id="cb341-18"><a href="bondad-de-ajuste.html#cb341-18"></a>  conteos &lt;-<span class="st"> </span><span class="kw">cut</span>(log_x, <span class="dt">breaks =</span> cortes)</span>
<span id="cb341-19"><a href="bondad-de-ajuste.html#cb341-19"></a>  conteos &lt;-<span class="st"> </span><span class="kw">summary</span>(conteos)</span>
<span id="cb341-20"><a href="bondad-de-ajuste.html#cb341-20"></a></span>
<span id="cb341-21"><a href="bondad-de-ajuste.html#cb341-21"></a>  l &lt;-<span class="st"> </span><span class="op">-</span><span class="kw">sum</span>(conteos <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(pi))</span>
<span id="cb341-22"><a href="bondad-de-ajuste.html#cb341-22"></a></span>
<span id="cb341-23"><a href="bondad-de-ajuste.html#cb341-23"></a>  <span class="kw">return</span>(l)</span>
<span id="cb341-24"><a href="bondad-de-ajuste.html#cb341-24"></a>}</span>
<span id="cb341-25"><a href="bondad-de-ajuste.html#cb341-25"></a></span>
<span id="cb341-26"><a href="bondad-de-ajuste.html#cb341-26"></a>sol &lt;-<span class="st"> </span><span class="kw">optim</span>(</span>
<span id="cb341-27"><a href="bondad-de-ajuste.html#cb341-27"></a>  <span class="dt">par =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb341-28"><a href="bondad-de-ajuste.html#cb341-28"></a>  <span class="dt">fn =</span> log_versomilitud,</span>
<span id="cb341-29"><a href="bondad-de-ajuste.html#cb341-29"></a>  <span class="dt">cortes =</span> cortes,</span>
<span id="cb341-30"><a href="bondad-de-ajuste.html#cb341-30"></a>  <span class="dt">log_x =</span> log_x</span>
<span id="cb341-31"><a href="bondad-de-ajuste.html#cb341-31"></a>)</span>
<span id="cb341-32"><a href="bondad-de-ajuste.html#cb341-32"></a></span>
<span id="cb341-33"><a href="bondad-de-ajuste.html#cb341-33"></a>sol<span class="op">$</span>par</span></code></pre></div>
<pre><code>## [1] 4.0926455 0.4331326</code></pre>
<p>Para otra solución, considere el siguiente teorema:</p>
<p><strong>Teorema</strong> (1954). <span class="math inline">\(X_1,\dots, X_n\sim F_\theta\)</span>, <span class="math inline">\(\theta: p\)</span>-dimensional.
<span class="math inline">\(\hat\theta_n\)</span> es el MLE de <span class="math inline">\(\theta\)</span> (basado en <span class="math inline">\(X_1,\dots, X_n\)</span>). Tome una
partición de <span class="math inline">\(\mathbb R\)</span> con <span class="math inline">\(k\)</span> intervalos disjuntos <span class="math inline">\((I_1,\dots,I_k)\)</span>. <span class="math inline">\(N_i\)</span>
es la cantidad de <span class="math inline">\(X_i\)</span>’s que pertenecen a <span class="math inline">\(I_i\)</span> y <span class="math inline">\(\pi_i(\theta)=\mathbb P_\theta[X_i\in I_i]\)</span>, <span class="math display">\[Q&#39; =
\sum_{i=1}^k\dfrac{[N_i-n\pi_i(\hat\theta_n)]^2}{n\pi_i(\hat\theta_n)}\]</span></p>
<p>Bajo las condiciones de regularidad del MLE, si <span class="math inline">\(n\to\infty\)</span>, el cdf de <span class="math inline">\(Q&#39;\)</span> bajo <span class="math inline">\(H_0\)</span> está entre <span class="math inline">\(\chi^2_{k-p-1}\)</span> y <span class="math inline">\(\chi^2_{k-1}\)</span>.</p>
<p>Del ejemplo anterior (tiempo de vida de los dispositivos), tome
<span class="math inline">\(\hat\mu = \bar X_n =4.1506137\)</span> y
<span class="math inline">\(\hat\sigma^2 = \dfrac{s_n^2}{n} = 0.5332049\)</span>.</p>
<ul>
<li><p><span class="math inline">\(\pi_1(\hat\mu,\hat\sigma^2) = \Phi\left(\dfrac{3.575-4.15}{0.2843^{1/2}}\right)-\Phi(-\infty) = 0.14\)</span>.</p></li>
<li><p><span class="math inline">\(\pi_2(\hat\mu,\hat\sigma^2) = \Phi\left(\dfrac{3.912-4.15}{0.2843^{1/2}}\right) - \Phi\left(\dfrac{3.575-4.15}{0.2843^{1/2}}\right) = 0.187\)</span>.</p></li>
<li><p><span class="math inline">\(\pi_3(\hat\mu,\hat\sigma^2) = \Phi\left(\dfrac{4.249-4.15}{0.2843^{1/2}}\right) - \Phi\left(\dfrac{3.912-4.15}{0.2843^{1/2}}\right) = 0.246\)</span>.</p></li>
<li><p><span class="math inline">\(\pi_4(\hat\mu,\hat\sigma^2) = 1 - \Phi\left(\dfrac{4.249-4.15}{0.2843^{1/2}}\right) = 0.4266\)</span>.</p></li>
</ul>
<p>Es decir podemos calcular lo siguiente en R</p>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="bondad-de-ajuste.html#cb343-1"></a>G &lt;-<span class="st"> </span><span class="kw">length</span>(cortes)</span>
<span id="cb343-2"><a href="bondad-de-ajuste.html#cb343-2"></a>mu &lt;-<span class="st"> </span><span class="kw">mean</span>(log_x)</span>
<span id="cb343-3"><a href="bondad-de-ajuste.html#cb343-3"></a>sigma &lt;-<span class="st"> </span><span class="kw">sd</span>(log_x)</span>
<span id="cb343-4"><a href="bondad-de-ajuste.html#cb343-4"></a></span>
<span id="cb343-5"><a href="bondad-de-ajuste.html#cb343-5"></a>pi &lt;-<span class="st"> </span><span class="kw">numeric</span>()</span>
<span id="cb343-6"><a href="bondad-de-ajuste.html#cb343-6"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>(G <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)) {</span>
<span id="cb343-7"><a href="bondad-de-ajuste.html#cb343-7"></a>  pi[k] &lt;-<span class="st"> </span><span class="kw">pnorm</span>(<span class="dt">q =</span> cortes[k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>], <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma) <span class="op">-</span></span>
<span id="cb343-8"><a href="bondad-de-ajuste.html#cb343-8"></a><span class="st">    </span><span class="kw">pnorm</span>(<span class="dt">q =</span> cortes[k], <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)</span>
<span id="cb343-9"><a href="bondad-de-ajuste.html#cb343-9"></a>}</span>
<span id="cb343-10"><a href="bondad-de-ajuste.html#cb343-10"></a></span>
<span id="cb343-11"><a href="bondad-de-ajuste.html#cb343-11"></a>pi</span></code></pre></div>
<pre><code>## [1] 0.1400819 0.1871877 0.2461242 0.4266062</code></pre>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="bondad-de-ajuste.html#cb345-1"></a><span class="kw">chisq.test</span>(conteos, <span class="dt">p =</span> pi)</span></code></pre></div>
<pre><code>## 
##  Chi-squared test for given probabilities
## 
## data:  conteos
## X-squared = 1.3381, df = 3, p-value = 0.7201</code></pre>
<p>Entonces</p>
<p><span class="math display">\[Q&#39; = \dfrac{(3-23\cdot 0.14)^2}{23\cdot 0.14} + \dfrac{(4-23\cdot
0.187)^2}{23\cdot 0.187} + \dfrac{(8-23\cdot 0.246)^2}{23\cdot 0.246}
+\dfrac{(8-23\cdot 0.4266)^2}{23\cdot 0.4266} = 1.3381.\]</span></p>
<ul>
<li><p><span class="math inline">\(\text{valor-}p_1 = F_{\chi^2_{4-2-1}}(1.3381) = 0.7526307\)</span>.</p></li>
<li><p><span class="math inline">\(\text{valor-}p_2 = F_{\chi^2_{4-1}}(1.3381) = 0.2798937\)</span>.</p></li>
</ul>
<p>Rechazamos <span class="math inline">\(H_0\)</span> (hipótesis de normalidad) si <span class="math inline">\(\alpha_0&lt;0.2798\)</span>.</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="bondad-de-ajuste.html#cb347-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="fl">2.5</span>, <span class="dv">6</span>)), <span class="kw">aes</span>(x)) <span class="op">+</span></span>
<span id="cb347-2"><a href="bondad-de-ajuste.html#cb347-2"></a><span class="st">  </span><span class="kw">geom_histogram</span>(</span>
<span id="cb347-3"><a href="bondad-de-ajuste.html#cb347-3"></a>    <span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> log_x),</span>
<span id="cb347-4"><a href="bondad-de-ajuste.html#cb347-4"></a>    <span class="kw">aes</span>(x, <span class="dt">y =</span> ..density..),</span>
<span id="cb347-5"><a href="bondad-de-ajuste.html#cb347-5"></a>    <span class="dt">color =</span> <span class="st">&quot;white&quot;</span></span>
<span id="cb347-6"><a href="bondad-de-ajuste.html#cb347-6"></a>  ) <span class="op">+</span></span>
<span id="cb347-7"><a href="bondad-de-ajuste.html#cb347-7"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb347-8"><a href="bondad-de-ajuste.html#cb347-8"></a>    <span class="dt">fun =</span> dnorm,</span>
<span id="cb347-9"><a href="bondad-de-ajuste.html#cb347-9"></a>    <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">log</span>(<span class="dv">50</span>), <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="fl">0.25</span>)),</span>
<span id="cb347-10"><a href="bondad-de-ajuste.html#cb347-10"></a>    <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Hipótesis Manual&quot;</span>),</span>
<span id="cb347-11"><a href="bondad-de-ajuste.html#cb347-11"></a>    <span class="dt">size =</span> <span class="dv">2</span></span>
<span id="cb347-12"><a href="bondad-de-ajuste.html#cb347-12"></a>  ) <span class="op">+</span></span>
<span id="cb347-13"><a href="bondad-de-ajuste.html#cb347-13"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb347-14"><a href="bondad-de-ajuste.html#cb347-14"></a>    <span class="dt">fun =</span> dnorm,</span>
<span id="cb347-15"><a href="bondad-de-ajuste.html#cb347-15"></a>    <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> sol<span class="op">$</span>par[<span class="dv">1</span>], <span class="dt">sd =</span> sol<span class="op">$</span>par[<span class="dv">2</span>]),</span>
<span id="cb347-16"><a href="bondad-de-ajuste.html#cb347-16"></a>    <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Hipótesis con Optimización&quot;</span>),</span>
<span id="cb347-17"><a href="bondad-de-ajuste.html#cb347-17"></a>    <span class="dt">size =</span> <span class="dv">2</span></span>
<span id="cb347-18"><a href="bondad-de-ajuste.html#cb347-18"></a>  ) <span class="op">+</span></span>
<span id="cb347-19"><a href="bondad-de-ajuste.html#cb347-19"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb347-20"><a href="bondad-de-ajuste.html#cb347-20"></a>    <span class="dt">fun =</span> dnorm,</span>
<span id="cb347-21"><a href="bondad-de-ajuste.html#cb347-21"></a>    <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(log_x), <span class="dt">sd =</span> <span class="kw">sd</span>(log_x)),</span>
<span id="cb347-22"><a href="bondad-de-ajuste.html#cb347-22"></a>    <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Hipótesis con MLE&quot;</span>),</span>
<span id="cb347-23"><a href="bondad-de-ajuste.html#cb347-23"></a>    <span class="dt">size =</span> <span class="dv">2</span></span>
<span id="cb347-24"><a href="bondad-de-ajuste.html#cb347-24"></a>  ) <span class="op">+</span></span>
<span id="cb347-25"><a href="bondad-de-ajuste.html#cb347-25"></a><span class="st">  </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/13-bondad-de-ajuste-9-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p><strong>Ejemplo</strong>. Suponga que se tiene el número de muertes por patadas de caballo en
el ejercito Prusiano.</p>
<table>
<thead>
<tr class="header">
<th><span class="math inline">\(\text{Conteos}\)</span></th>
<th><span class="math inline">\(0\)</span></th>
<th><span class="math inline">\(1\)</span></th>
<th><span class="math inline">\(2\)</span></th>
<th><span class="math inline">\(3\)</span></th>
<th><span class="math inline">\(\ge 4\)</span></th>
<th><span class="math inline">\(\text{Total}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\text{Núm. de obs.}\)</span></td>
<td><span class="math inline">\(144\)</span></td>
<td><span class="math inline">\(91\)</span></td>
<td><span class="math inline">\(32\)</span></td>
<td><span class="math inline">\(11\)</span></td>
<td><span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(280\)</span></td>
</tr>
</tbody>
</table>
<p>¿Será la variable Poisson?</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="bondad-de-ajuste.html#cb348-1"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(</span>
<span id="cb348-2"><a href="bondad-de-ajuste.html#cb348-2"></a>  <span class="dt">conteos =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>),</span>
<span id="cb348-3"><a href="bondad-de-ajuste.html#cb348-3"></a>  <span class="dt">observaciones =</span> <span class="kw">c</span>(<span class="dv">144</span>, <span class="dv">91</span>, <span class="dv">32</span>, <span class="dv">11</span>, <span class="dv">2</span>)</span>
<span id="cb348-4"><a href="bondad-de-ajuste.html#cb348-4"></a>)</span>
<span id="cb348-5"><a href="bondad-de-ajuste.html#cb348-5"></a></span>
<span id="cb348-6"><a href="bondad-de-ajuste.html#cb348-6"></a><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> conteos, <span class="dt">y =</span> observaciones)) <span class="op">+</span></span>
<span id="cb348-7"><a href="bondad-de-ajuste.html#cb348-7"></a><span class="st">  </span><span class="kw">geom_col</span>() <span class="op">+</span></span>
<span id="cb348-8"><a href="bondad-de-ajuste.html#cb348-8"></a><span class="st">  </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/13-bondad-de-ajuste-10-1.svg" width="100%" style="display: block; margin: auto;" /></p>
<p><span class="math inline">\(H_0: f = \text{Poisson}(\theta), \theta&gt;0\)</span>.</p>
<p>El MLE de <span class="math inline">\(\hat\theta\)</span> es</p>
<p><span class="math display">\[\dfrac{0\cdot 144+1\cdot91+2\cdot32+3\cdot 11+2\cdot4}{280} = \dfrac{196}{280} = 0.7\]</span></p>
<ul>
<li><p><span class="math inline">\(\pi_1(\hat\theta) = e^{-\hat\theta} = e^{-0.7}=0.4966\)</span>.</p></li>
<li><p><span class="math inline">\(\pi_2(\hat\theta) = \dfrac{e^{-\hat\theta}\hat\theta}{1!} = 0.3476\)</span>.</p></li>
<li><p><span class="math inline">\(\pi_3(\hat\theta) = \dfrac{e^{-\hat\theta}\hat\theta^2}{2!} = 0.1217\)</span>.</p></li>
<li><p><span class="math inline">\(\pi_4(\hat\theta) = \dfrac{e^{-\hat\theta}\hat\theta^3}{3!} = 0.0283\)</span>.</p></li>
<li><p><span class="math inline">\(\pi_5(\hat\theta) = \bar F_{\text{Poisson}(\hat\theta)}(4) = 0.0058\)</span></p></li>
</ul>
<p><span class="math display">\[\begin{align*}
Q&#39; &amp; = \dfrac{(144-280\cdot0.4966)^2}{280\cdot0.4966}+\dfrac{(91-280\cdot0.3476)^2}{280\cdot0.3476}+\dfrac{(32-280\cdot0.1217)^2}{280\cdot0.1217}\\
&amp; +\dfrac{(11-280\cdot0.0283)^2}{280\cdot0.0283} +\dfrac{(2-280\cdot0.0058)^2}{280\cdot0.0058} = 1.979.
\end{align*}\]</span></p>
<ul>
<li><p><span class="math inline">\(\text{valor-}p_1 = F_{\chi^2_{5-1-1}}(1.979) = 0.5768\)</span>.</p></li>
<li><p><span class="math inline">\(\text{valor-}p_2 = F_{\chi^2_{5-1}}(1.979) = 0.7396\)</span>.</p></li>
</ul>
<p><em>Interpretación</em>: con un nivel de significancia del 5% no rechazamos la hipótesis Poisson en los datos.</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="bondad-de-ajuste.html#cb349-1"></a>total &lt;-<span class="st"> </span><span class="kw">sum</span>(df<span class="op">$</span>observaciones)</span>
<span id="cb349-2"><a href="bondad-de-ajuste.html#cb349-2"></a></span>
<span id="cb349-3"><a href="bondad-de-ajuste.html#cb349-3"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">4</span>)), <span class="kw">aes</span>(x)) <span class="op">+</span></span>
<span id="cb349-4"><a href="bondad-de-ajuste.html#cb349-4"></a><span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">data =</span> df, <span class="kw">aes</span>(<span class="dt">x =</span> conteos, <span class="dt">y =</span> observaciones <span class="op">/</span><span class="st"> </span>total)) <span class="op">+</span></span>
<span id="cb349-5"><a href="bondad-de-ajuste.html#cb349-5"></a><span class="st">  </span><span class="kw">stat_function</span>(</span>
<span id="cb349-6"><a href="bondad-de-ajuste.html#cb349-6"></a>    <span class="dt">fun =</span> dpois,</span>
<span id="cb349-7"><a href="bondad-de-ajuste.html#cb349-7"></a>    <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">lambda =</span> <span class="fl">0.7</span>),</span>
<span id="cb349-8"><a href="bondad-de-ajuste.html#cb349-8"></a>    <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Hipótesis con MLE&quot;</span>),</span>
<span id="cb349-9"><a href="bondad-de-ajuste.html#cb349-9"></a>    <span class="dt">size =</span> <span class="dv">2</span>,</span>
<span id="cb349-10"><a href="bondad-de-ajuste.html#cb349-10"></a>    <span class="dt">geom =</span> <span class="st">&quot;col&quot;</span></span>
<span id="cb349-11"><a href="bondad-de-ajuste.html#cb349-11"></a>  ) <span class="op">+</span></span>
<span id="cb349-12"><a href="bondad-de-ajuste.html#cb349-12"></a><span class="st">  </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/13-bondad-de-ajuste-11-1.svg" width="100%" style="display: block; margin: auto;" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="prueba-de-comparación-de-medias-en-2-poblaciones.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tablas-de-contingencia.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica-parte-1/edit/master/13-bondad-de-ajuste.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica-parte-1/blob/master/13-bondad-de-ajuste.Rmd",
"text": null
},
"download": ["Notas-Curso-Estadistica.pdf"],
"toc": {
"collapse": "subsection"
},
"toc_depth": 5
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
