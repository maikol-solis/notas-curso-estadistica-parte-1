<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 6 Distribución muestral de un estadístico | Notas Curso de Estadística (Parte I)</title>
  <meta name="description" content="Capítulo 6 Distribución muestral de un estadístico | Notas Curso de Estadística (Parte I)" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 6 Distribución muestral de un estadístico | Notas Curso de Estadística (Parte I)" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 6 Distribución muestral de un estadístico | Notas Curso de Estadística (Parte I)" />
  
  
  

<meta name="author" content="Maikol Solís" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estadísticos-suficientes-y-criterio-de-factorización.html"/>
<link rel="next" href="intervalos-de-confianza.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html"><i class="fa fa-check"></i><b>2</b> Inferencia estadística</a>
<ul>
<li class="chapter" data-level="2.1" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#ejemplo"><i class="fa fa-check"></i><b>2.1</b> Ejemplo</a></li>
<li class="chapter" data-level="2.2" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#modelo-estadístico"><i class="fa fa-check"></i><b>2.2</b> Modelo estadístico</a></li>
<li class="chapter" data-level="2.3" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#estadístico"><i class="fa fa-check"></i><b>2.3</b> Estadístico</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><i class="fa fa-check"></i><b>3</b> Densidades previas conjugadas y estimadores de Bayes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-previa-distribución-a-priori"><i class="fa fa-check"></i><b>3.1</b> Distribución previa (distribución a priori)</a></li>
<li class="chapter" data-level="3.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#densidad-posterior"><i class="fa fa-check"></i><b>3.2</b> Densidad posterior</a></li>
<li class="chapter" data-level="3.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#proceso-de-modelación-de-parámetros."><i class="fa fa-check"></i><b>3.3</b> Proceso de modelación de parámetros.</a></li>
<li class="chapter" data-level="3.4" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-verosimilitud"><i class="fa fa-check"></i><b>3.4</b> Función de verosimilitud</a></li>
<li class="chapter" data-level="3.5" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#familias-conjugadas"><i class="fa fa-check"></i><b>3.5</b> Familias conjugadas</a></li>
<li class="chapter" data-level="3.6" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#densidades-previas-impropias"><i class="fa fa-check"></i><b>3.6</b> Densidades previas impropias</a></li>
<li class="chapter" data-level="3.7" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#funciones-de-pérdida"><i class="fa fa-check"></i><b>3.7</b> Funciones de pérdida</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-pérdida-cuadrática"><i class="fa fa-check"></i><b>3.7.1</b> Función de pérdida cuadrática</a></li>
<li class="chapter" data-level="3.7.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-pérdida-absoluta"><i class="fa fa-check"></i><b>3.7.2</b> Función de pérdida absoluta</a></li>
<li class="chapter" data-level="3.7.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#otras-funciones-de-pérdida"><i class="fa fa-check"></i><b>3.7.3</b> Otras funciones de pérdida</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#efecto-de-muestras-grandes"><i class="fa fa-check"></i><b>3.8</b> Efecto de muestras grandes</a></li>
<li class="chapter" data-level="3.9" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#consistencia"><i class="fa fa-check"></i><b>3.9</b> Consistencia</a></li>
<li class="chapter" data-level="3.10" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#laboratorio"><i class="fa fa-check"></i><b>3.10</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-previa"><i class="fa fa-check"></i><b>3.10.1</b> Distribución previa</a></li>
<li class="chapter" data-level="3.10.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-conjunta"><i class="fa fa-check"></i><b>3.10.2</b> Distribución conjunta</a></li>
<li class="chapter" data-level="3.10.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-posterior"><i class="fa fa-check"></i><b>3.10.3</b> Distribución posterior</a></li>
<li class="chapter" data-level="3.10.4" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#agregando-nuevos-datos"><i class="fa fa-check"></i><b>3.10.4</b> Agregando nuevos datos</a></li>
<li class="chapter" data-level="3.10.5" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#familias-conjugadas-normales"><i class="fa fa-check"></i><b>3.10.5</b> Familias conjugadas normales</a></li>
<li class="chapter" data-level="3.10.6" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#funciones-de-pérdida-1"><i class="fa fa-check"></i><b>3.10.6</b> Funciones de pérdida</a></li>
<li class="chapter" data-level="3.10.7" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#caso-concreto"><i class="fa fa-check"></i><b>3.10.7</b> Caso concreto</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html"><i class="fa fa-check"></i><b>4</b> Estimación por máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="4.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#propiedades-del-mle"><i class="fa fa-check"></i><b>4.1</b> Propiedades del MLE</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#propiedad-de-invarianza"><i class="fa fa-check"></i><b>4.1.1</b> Propiedad de invarianza</a></li>
<li class="chapter" data-level="4.1.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#consistencia-1"><i class="fa fa-check"></i><b>4.1.2</b> Consistencia</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#cálculo-numérico"><i class="fa fa-check"></i><b>4.2</b> Cálculo numérico</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#método-de-los-momentos"><i class="fa fa-check"></i><b>4.2.1</b> Método de los momentos</a></li>
<li class="chapter" data-level="4.2.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#método-delta"><i class="fa fa-check"></i><b>4.2.2</b> Método Delta</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#laboratorio-1"><i class="fa fa-check"></i><b>4.3</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html"><i class="fa fa-check"></i><b>5</b> Estadísticos Suficientes y Criterio de Factorización</a>
<ul>
<li class="chapter" data-level="5.1" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadísticos-suficientes"><i class="fa fa-check"></i><b>5.1</b> Estadísticos suficientes</a></li>
<li class="chapter" data-level="5.2" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#teorema-de-factorización-de-fisher"><i class="fa fa-check"></i><b>5.2</b> Teorema de Factorización de Fisher</a></li>
<li class="chapter" data-level="5.3" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadístico-suficiente-multivariado."><i class="fa fa-check"></i><b>5.3</b> Estadístico suficiente multivariado.</a></li>
<li class="chapter" data-level="5.4" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadísticos-minimales"><i class="fa fa-check"></i><b>5.4</b> Estadísticos minimales</a></li>
<li class="chapter" data-level="5.5" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#mejorando-estimadores"><i class="fa fa-check"></i><b>5.5</b> Mejorando estimadores</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html"><i class="fa fa-check"></i><b>6</b> Distribución muestral de un estadístico</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-muestral"><i class="fa fa-check"></i><b>6.1</b> Distribución muestral</a></li>
<li class="chapter" data-level="6.2" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-chi2"><i class="fa fa-check"></i><b>6.2</b> Distribución <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="6.3" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-t"><i class="fa fa-check"></i><b>6.3</b> Distribución <span class="math inline">\(t\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>7</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="7.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-la-media-de-una-distribución-normal"><i class="fa fa-check"></i><b>7.1</b> Intervalos de confianza para la media de una distribución normal</a></li>
<li class="chapter" data-level="7.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#caso-normal."><i class="fa fa-check"></i><b>7.2</b> Caso normal.</a></li>
<li class="chapter" data-level="7.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-abiertos"><i class="fa fa-check"></i><b>7.3</b> Intervalos de confianza abiertos</a></li>
<li class="chapter" data-level="7.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-en-otros-casos"><i class="fa fa-check"></i><b>7.4</b> Intervalos de confianza en otros casos</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-aproximados."><i class="fa fa-check"></i><b>7.4.1</b> Intervalos de confianza aproximados.</a></li>
<li class="chapter" data-level="7.4.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#transformaciones-estabilizadoras-de-la-varianza"><i class="fa fa-check"></i><b>7.4.2</b> Transformaciones estabilizadoras de la varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html"><i class="fa fa-check"></i><b>8</b> Estimación Bayesiana bajo normalidad</a>
<ul>
<li class="chapter" data-level="8.1" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#precisión-de-una-distribución-normal"><i class="fa fa-check"></i><b>8.1</b> Precisión de una distribución normal</a></li>
<li class="chapter" data-level="8.2" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#distribución-marginal-de-mu"><i class="fa fa-check"></i><b>8.2</b> Distribución marginal de <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="8.3" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#intervalos-de-credibilidad."><i class="fa fa-check"></i><b>8.3</b> Intervalos de credibilidad.</a></li>
<li class="chapter" data-level="8.4" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#efecto-de-previas-no-informativas-opcional"><i class="fa fa-check"></i><b>8.4</b> Efecto de previas no informativas (Opcional)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html"><i class="fa fa-check"></i><b>9</b> Estimación insesgada</a>
<ul>
<li class="chapter" data-level="9.1" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimadores-insesgados"><i class="fa fa-check"></i><b>9.1</b> Estimadores insesgados</a></li>
<li class="chapter" data-level="9.2" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimador-insesgado-de-la-varianza"><i class="fa fa-check"></i><b>9.2</b> Estimador insesgado de la varianza</a></li>
<li class="chapter" data-level="9.3" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#información-de-fisher"><i class="fa fa-check"></i><b>9.3</b> Información de Fisher</a></li>
<li class="chapter" data-level="9.4" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#desigualdad-de-cramer-rao"><i class="fa fa-check"></i><b>9.4</b> Desigualdad de Cramer-Rao</a></li>
<li class="chapter" data-level="9.5" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimadores-eficientes"><i class="fa fa-check"></i><b>9.5</b> Estimadores eficientes</a></li>
<li class="chapter" data-level="9.6" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#comportamiento-asintótico-del-mle"><i class="fa fa-check"></i><b>9.6</b> Comportamiento asintótico del MLE</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>10</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-hipótesis-1"><i class="fa fa-check"></i><b>10.1</b> Pruebas de hipótesis</a></li>
<li class="chapter" data-level="10.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#regiones-críticas-y-estadísticas-de-prueba"><i class="fa fa-check"></i><b>10.2</b> Regiones críticas y estadísticas de prueba</a></li>
<li class="chapter" data-level="10.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#función-de-potencia-y-tipos-de-error"><i class="fa fa-check"></i><b>10.3</b> Función de potencia y tipos de error</a></li>
<li class="chapter" data-level="10.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#valor-p"><i class="fa fa-check"></i><b>10.4</b> Valor <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="10.5" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#dualidad-entre-pruebas-de-hipótesis-y-regiones-de-confianza"><i class="fa fa-check"></i><b>10.5</b> Dualidad entre pruebas de hipótesis y regiones de confianza</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#dualidad-en-pruebas-unilaterales"><i class="fa fa-check"></i><b>10.5.1</b> Dualidad en pruebas unilaterales</a></li>
<li class="chapter" data-level="10.5.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-cociente-de-verosimilitud-lrt"><i class="fa fa-check"></i><b>10.5.2</b> Pruebas de cociente de verosimilitud (LRT)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html"><i class="fa fa-check"></i><b>11</b> Pruebas con hipótesis simples</a>
<ul>
<li class="chapter" data-level="11.1" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#hipótesis-simples"><i class="fa fa-check"></i><b>11.1</b> Hipótesis simples</a></li>
<li class="chapter" data-level="11.2" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#criterio-de-neyman-pearson"><i class="fa fa-check"></i><b>11.2</b> Criterio de Neyman-Pearson</a></li>
<li class="chapter" data-level="11.3" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#pruebas-insesgadas"><i class="fa fa-check"></i><b>11.3</b> Pruebas insesgadas</a></li>
<li class="chapter" data-level="11.4" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#prueba-t"><i class="fa fa-check"></i><b>11.4</b> Prueba <span class="math inline">\(t\)</span></a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#propiedades-de-las-pruebas-t"><i class="fa fa-check"></i><b>11.4.1</b> Propiedades de las pruebas <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="11.4.2" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#prueba-t-pareada"><i class="fa fa-check"></i><b>11.4.2</b> Prueba <span class="math inline">\(t\)</span> pareada</a></li>
<li class="chapter" data-level="11.4.3" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#pruebas-t-de-dos-colas"><i class="fa fa-check"></i><b>11.4.3</b> Pruebas <span class="math inline">\(t\)</span> de dos colas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html"><i class="fa fa-check"></i><b>12</b> Prueba de comparación de medias en 2 poblaciones</a>
<ul>
<li class="chapter" data-level="12.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#comparación-de-medias-normales"><i class="fa fa-check"></i><b>12.1</b> Comparación de medias normales</a></li>
<li class="chapter" data-level="12.2" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-t-de-dos-muestras"><i class="fa fa-check"></i><b>12.2</b> Prueba <span class="math inline">\(t\)</span> de dos muestras</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-de-2-colas"><i class="fa fa-check"></i><b>12.2.1</b> Prueba de 2 colas</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-f"><i class="fa fa-check"></i><b>12.3</b> Prueba <span class="math inline">\(F\)</span></a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-de-2-colas-prueba-de-homocedasticidad"><i class="fa fa-check"></i><b>12.3.1</b> Prueba de 2 colas (prueba de homocedasticidad)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html"><i class="fa fa-check"></i><b>13</b> Bondad de ajuste</a>
<ul>
<li class="chapter" data-level="13.1" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html#prueba-chi2"><i class="fa fa-check"></i><b>13.1</b> Prueba <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="13.2" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html#pruebas-chi2-con-hipótesis-parametrizadas"><i class="fa fa-check"></i><b>13.2</b> Pruebas <span class="math inline">\(\chi^2\)</span> con hipótesis parametrizadas</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html"><i class="fa fa-check"></i><b>14</b> Tablas de contingencia</a>
<ul>
<li class="chapter" data-level="14.1" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#prueba-de-independencia"><i class="fa fa-check"></i><b>14.1</b> Prueba de independencia</a></li>
<li class="chapter" data-level="14.2" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#prueba-de-homogeneidad"><i class="fa fa-check"></i><b>14.2</b> Prueba de homogeneidad</a></li>
<li class="chapter" data-level="14.3" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#similitudes-entre-las-pruebas-de-independecia-y-homogeneidad"><i class="fa fa-check"></i><b>14.3</b> Similitudes entre las pruebas de independecia y homogeneidad</a></li>
<li class="chapter" data-level="14.4" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#comparación-de-dos-o-más-proporciones"><i class="fa fa-check"></i><b>14.4</b> Comparación de dos o más proporciones</a></li>
<li class="chapter" data-level="14.5" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#paradoja-de-simpson"><i class="fa fa-check"></i><b>14.5</b> Paradoja de Simpson</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#cómo-evitamos-esta-paradoja"><i class="fa fa-check"></i><b>14.5.1</b> ¿Cómo evitamos esta paradoja?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="pruebas-de-kolmogorov-smirnov.html"><a href="pruebas-de-kolmogorov-smirnov.html"><i class="fa fa-check"></i><b>15</b> Pruebas de Kolmogorov-Smirnov</a>
<ul>
<li class="chapter" data-level="15.1" data-path="pruebas-de-kolmogorov-smirnov.html"><a href="pruebas-de-kolmogorov-smirnov.html#prueba-de-kolmogorov-smirnov-para-una-muestra"><i class="fa fa-check"></i><b>15.1</b> Prueba de Kolmogorov-Smirnov para una muestra</a></li>
<li class="chapter" data-level="15.2" data-path="pruebas-de-kolmogorov-smirnov.html"><a href="pruebas-de-kolmogorov-smirnov.html#prueba-de-2-muestras"><i class="fa fa-check"></i><b>15.2</b> Prueba de 2 muestras</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html"><a href="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html"><i class="fa fa-check"></i><b>16</b> Pruebas no-paramétricas: pruebas de signo y rango</a>
<ul>
<li class="chapter" data-level="16.1" data-path="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html"><a href="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html#prueba-de-signo"><i class="fa fa-check"></i><b>16.1</b> Prueba de signo</a></li>
<li class="chapter" data-level="16.2" data-path="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html"><a href="pruebas-no-paramétricas-pruebas-de-signo-y-rango.html#prueba-de-wilconxon-mann-whitney"><i class="fa fa-check"></i><b>16.2</b> Prueba de Wilconxon-Mann-Whitney</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html"><i class="fa fa-check"></i><b>17</b> Ejercicios varios</a>
<ul>
<li class="chapter" data-level="17.1" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html#capítulo-8"><i class="fa fa-check"></i><b>17.1</b> Capítulo 8</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html#section"><i class="fa fa-check"></i><b>17.1.1</b> 8.4.6</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas Curso de Estadística (Parte I)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="distribución-muestral-de-un-estadístico" class="section level1" number="6">
<h1><span class="header-section-number">Capítulo 6</span> Distribución muestral de un estadístico</h1>
<div id="distribución-muestral" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Distribución muestral</h2>
<p><strong>Definición</strong>. Suponga que <span class="math inline">\(X_1,\dots,X_n\)</span> es una muestra con parámetro
<span class="math inline">\(\theta\)</span> con parámetro <span class="math inline">\(\theta\)</span> (desconocido). Sea <span class="math inline">\(T=r(X_1,\dots,X_n,\theta)\)</span>. La
distribución de <span class="math inline">\(T\)</span> dado <span class="math inline">\(\theta\)</span> se llama <strong>distribución muestral</strong>.</p>
<p><strong>Ejemplo</strong>. Si <span class="math inline">\(X_1,\dots,X_n \sim N(\mu,\sigma^2)\)</span>. El MLE de <span class="math inline">\(\mu\)</span> es</p>
<p><span class="math display">\[\begin{equation*}
\bar X_n =\dfrac 1n \sum_{i=1}^n X_i.
\end{equation*}\]</span></p>
<p>La distribución muestral del estadístico <span class="math inline">\(\bar X_n\)</span> es</p>
<p><span class="math display">\[
\bar X_n \sim N\left(\mu, \dfrac{\sigma^2}n \right)
\]</span></p>
<ul>
<li><p><span class="math inline">\(\mathbb E[\bar X_n] = \dfrac 1n\displaystyle\sum_{i=1}^n\mathbb E[X_i] = \dfrac 1n\cdot n \mathbb E[X_1] = \mu\)</span>.</p></li>
<li><p><span class="math inline">\(\text{Var}(\bar X_n) = \text{Var}\left(\dfrac 1n \displaystyle\sum_{i=1}^n X_i\right) = \dfrac{1}{n^2}\cdot n\cdot \text{Var}(X_1) = \dfrac{\sigma^2}n\)</span>.</p></li>
</ul>
<p><strong>Ejemplo</strong>. <span class="math inline">\(X_i:\)</span> tiempo de vida de un aparato. <span class="math inline">\(X_1,\dots,X_n \stackrel{i.i.d}{\sim} \text{Exp}(\theta)\)</span>. La previa de <span class="math inline">\(\theta\)</span> es <span class="math inline">\(\Gamma(1,2)\)</span>. Solamente
observamos <span class="math inline">\(n=3\)</span>. La posterior sería</p>
<p><span class="math display">\[
\theta|X \sim \Gamma(1+3,2+\sum_{i=1}^3 X_i). 
\]</span></p>
<p>El estimador bayesiano, bajo pérdida cuadrática, es
<span class="math display">\[
\mathbb E[\theta|X] = \dfrac 4{2+\sum X_i} = \hat\theta
\]</span></p>
<p><strong>Problema:</strong> estimar <span class="math inline">\(\mathbb P(|\hat\theta-\theta|&lt;0.1)\)</span>.</p>
<p>Note que</p>
<p><span class="math display">\[\begin{align*}
\mathbb P(|\hat\theta-\theta|&lt;0.1)
&amp;= \mathbb E [1_{|\hat\theta-\theta|&lt;0.1|\theta)}] \\
&amp;= \mathbb E[\mathbb E [1_{|\hat\theta-\theta|&lt;0.1|\theta)}\vert \theta]] \\
&amp;= \mathbb E[\mathbb P(|\hat\theta-\theta|&lt;0.1|\theta)]
\end{align*}\]</span></p>
<p>Debemos definir primero cuál es la función de distribución de <span class="math inline">\(\hat{\theta}\)</span>.</p>
<p><span class="math display">\[\begin{align*}
F_{\hat{\theta}}(t|\theta) = \mathbb P(\hat\theta\leq t|\theta)&amp;= \mathbb
P\left( \dfrac 4{2+T}\leq t\bigg|\theta\right) \\ &amp; = \mathbb P\left( 2+T \geq
\dfrac 4t\bigg|\theta\right)\\ &amp; = \mathbb P\left( T \geq \dfrac
4t-2\bigg|\theta\right)
\end{align*}\]</span></p>
<p><strong>Nota: Recuerde que sumas de exponenciales es una gamma. (Ver teorema 5.7.7)</strong></p>
<p>Entonces <span class="math inline">\(T=\sum_{i=1}^{3}X_{i}\sim \Gamma(3,\theta)\)</span>, por lo que <span class="math inline">\(F(t|\theta) = 1-G_{\Gamma(3,0)}\left( \dfrac 4t-2\right)\)</span>. Aqui denotamos como <span class="math inline">\(G\)</span> a la
distribución de <span class="math inline">\(T\)</span>.</p>
<p>De esta manera,</p>
<p><span class="math display">\[\begin{align*}
\mathbb P[|\hat\theta-\theta|&lt;0.1|\theta]  
&amp; = \mathbb P [-0.1+\theta &lt; \hat\theta &lt; 0.1 +\theta|\theta]\\
&amp; = G_{\Gamma(3,\theta)}\left(\dfrac 4{-0.1+\theta} - 2\right)-G_{\Gamma(3,\theta)}\left(\dfrac 4{0.1+\theta} - 2\right)
\end{align*}\]</span></p>
<p>y se toma la esperanza para estimar la esperanza. Este valor no se puede estimar
de forma cerrada, sino que se podría aproximar mediante una simulación</p>
<p><img src="images/gamma_mle_vs_posterior.png" /></p>
<p>Otra solución es estimar <span class="math inline">\(\theta\)</span> usando el MLE <span class="math inline">\(\hat{\theta} = \frac{3}{T}\)</span>. Se
podría construir esa probabilidad de forma que no dependa de <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[
\mathbb P \left(\bigg| \underbrace{\dfrac{\hat\theta_{MLE}}\theta-1}_{\text{Cambio
relativo}} \bigg| &lt; 0.1\bigg|\theta \right) = \mathbb P \left( \bigg| \dfrac{3}{\theta
T}-1 \bigg| &lt; 0.1 \bigg| \theta \right) = \Delta \]</span></p>
<p>Si <span class="math inline">\(T\sim\Gamma(3,\theta) \implies \theta T \sim \Gamma(3,1)\)</span>.</p>
<p>Por lo tanto,
<span class="math display">\[
\Delta = \mathbb P \left(0.9&lt;\dfrac 3{\theta T}&lt;1.1\bigg|\theta\right) = \mathbb P \left(\dfrac 3{1.1}&lt;\theta T&lt;\dfrac 3{0.9}\right) = 13,4\%
\]</span></p>
</div>
<div id="distribución-chi2" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Distribución <span class="math inline">\(\chi^2\)</span></h2>
<p><strong>Definición</strong>. Para <span class="math inline">\(m&gt;0\)</span> definimos
<span class="math display">\[
\chi^2_m \sim \Gamma\left(\dfrac m2, \dfrac 12 \right)
\]</span></p>
<p>la distribución <strong>chi-cuadrado</strong> con <span class="math inline">\(m\)</span> grados de libertad.</p>
<p><strong>Propiedades</strong>:</p>
<ul>
<li><p><span class="math inline">\(\mathbb E[X] = m\)</span>.</p></li>
<li><p><span class="math inline">\(\text{Var} (X) = 2m\)</span>.</p></li>
<li><p>Para <span class="math inline">\(X_i \sim \chi^2_{m_i}\)</span>, <span class="math inline">\(i = 1,\dots, k\)</span>, independientes, entonces</p></li>
</ul>
<p><span class="math display">\[\sum_{i=1}^k X_i \sim \chi^2_{\sum m_i}\]</span></p>
<ul>
<li><p>Si <span class="math inline">\(X\sim N(0,1) \implies Y = X^2\sim \chi^2_1\)</span>.</p></li>
<li><p>Si <span class="math inline">\(X_i \stackrel{i.i.d}{\sim} N(0,1) \implies \sum_{i=1}^m X_i^2 = \chi^2_m\)</span>.</p></li>
</ul>
<p><strong>Ejemplo</strong>. Si <span class="math inline">\(X_1,\dots,X_n \sim N(\mu,\sigma^2) \implies Z = \dfrac{X_i-\mu}{\sigma} \sim N(0,1)\)</span> <span class="math inline">\(\forall i\)</span>.</p>
<p>Entonces
<span class="math display">\[\sum Z_i^2 \sim \chi^2_n \implies \sum \dfrac{(X_i-\mu)^2}{\sigma^2}\sim \chi^2_n \quad (\*) \]</span></p>
<p>Además, si <span class="math inline">\(\mu\)</span> es conocido y <span class="math inline">\(\sigma^2\)</span> desconocido, entonces el MLE de <span class="math inline">\(\sigma ^{2}\)</span> es
<span class="math display">\[\hat\sigma_0^2=\dfrac{1}n \sum_{i=1}^n(X_i-\mu)^2\]</span></p>
<p>De esta manera, observe que, de <span class="math inline">\((*)\)</span>,</p>
<p><span class="math display">\[\dfrac{n}{\sigma^2} \dfrac{1}n \sum_{i=1}^n(X_i-\mu)^2 = n\dfrac{\hat \sigma_{0}^2}{\sigma^2} \sim \chi^2_n \]</span></p>
<p>La principal limitación es que <span class="math inline">\(\mu\)</span> es conocida. Asuma que también es
desconocida. ¿Cuál es la distribución muestral de <span class="math inline">\((\bar X_n,\hat\sigma^2)\)</span>?</p>
<p><strong>Teorema</strong>. Bajo las condiciones anteriores,</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\bar X_n\)</span> y <span class="math inline">\(\hat \sigma_n\)</span> son independientes aunque <span class="math inline">\(\hat \sigma_n\)</span> es función de
<span class="math inline">\(\bar X_n\)</span>.</p></li>
<li><p>La distribución muestral de <span class="math inline">\(\bar X_n\)</span> es <span class="math inline">\(N\left(\mu,\dfrac{\sigma^2}{n}\right)\)</span>.</p></li>
<li><p><span class="math inline">\(n\dfrac{\hat \sigma_{0}^2}{\sigma^2} =\sum_{i=1}^n \dfrac{(X_i-\mu)^2}{\sigma^2} \sim \chi^2_{n-1}\)</span>.</p></li>
</ol>
<p><strong>Nota:</strong> De álgebra lineal, recuerde que una matriz <span class="math inline">\(A_{n\times n}\)</span> es ortogonal si
cumple que <span class="math inline">\(A^{-1} = A\)</span>, <span class="math inline">\(\det(A) = 1\)</span>. Si <span class="math inline">\(X, Y\in \mathbb R ^{n}\)</span>, <span class="math inline">\(AX =Y\)</span>, <span class="math inline">\(A\)</span>
ortogonal, entonces <span class="math display">\[ \|Y\|_2^2 = \|X\|_2^2 \quad (\Delta\Delta)\]</span></p>
<p><strong>Teorema</strong>. Si <span class="math inline">\(X_1,\dots,X_n \sim N(0,1)\)</span>, <span class="math inline">\(A\)</span> es ortogonal <span class="math inline">\(n\times n\)</span> y <span class="math inline">\(Y=AX\)</span> donde
<span class="math inline">\(X = (X_1,\dots,X_n)^T\)</span> entonces <span class="math inline">\(Y_1,\dots,Y_n \sim N(0,1)\)</span>.</p>
<p><em>Prueba</em>. Ver 8.3.1.</p>
<p>Si <span class="math inline">\(X_1,\dots,X_n \sim N(0,1)\)</span>, use Gram-Schmidt con vector inicial</p>
<p><span class="math display">\[\begin{equation*}
u = \left[ \frac{1}{\sqrt{n}}, \cdots, \frac{1}{\sqrt{n}}\right]
\end{equation*}\]</span></p>
<p>Generamos <span class="math inline">\(A = \begin{bmatrix}u\\\vdots\end{bmatrix}\)</span>. Defina <span class="math inline">\(Y =AX\)</span>. Entonces <span class="math display">\[ Y_1 = uX = \dfrac 1{\sqrt{n}}\sum_{i=1}^n X_i = \sqrt{n} \bar
X_n.\]</span></p>
<p>Por la propiedad <span class="math inline">\((\Delta \Delta)\)</span>, <span class="math inline">\(\displaystyle\sum_{i=1}^n Y_i^2 = \displaystyle\sum_{i=1}^n X_i^2\)</span>. Entonces,
<span class="math display">\[ \sum_{i=2}^nY_i^2 = \sum_{i=1}^nY_i^2 - Y_1^2 = \sum_{i=1}^nX_i^2-n\bar X_n^2\sum_{i=1}^n(X_i-\bar X_n)^2. \]</span></p>
<p>Como <span class="math inline">\(Y_1^2\)</span> y <span class="math inline">\(\sum_{i=2}^nY_i^2\)</span> son independientes, entonces <span class="math inline">\(\bar X_n\)</span> y <span class="math inline">\(\dfrac{1}n \sum_{i=1}^n(X_i-\bar X_n)^2\)</span> son independientes.</p>
<p>Note que <span class="math inline">\(\sum_{i=2}^n Y_i^2 \sim \chi^2_{n-1}\)</span> ya que <span class="math inline">\(Y_i \stackrel{i.i.d}{\sim} N(0,1)\)</span>.</p>
<p>Si <span class="math inline">\(X_1,\dots,X_n \sim N(\mu, \sigma^2)\)</span>, tome <span class="math inline">\(Z_i = \dfrac{X_i-\mu}\sigma\)</span> y repita todo lo anterior.</p>
<p><strong>Ejemplo</strong>. <span class="math inline">\(X_1,\dots,X_n\sim N(\mu,\sigma^2)\)</span> (<span class="math inline">\(\mu,\sigma\)</span> desconocidos). Los MLE son</p>
<p><span class="math display">\[\hat \mu = \bar X_n,\quad \hat\sigma = \bigg[\dfrac{1}{n}\sum_{i=1}^n(X_i-\bar X_n)^2 \bigg]^{\frac 12}.\]</span></p>
<p>Encuentre <span class="math inline">\(n\)</span> tal que</p>
<p><span class="math display">\[\begin{equation*}
p = \mathbb P \bigg[|\hat\mu-\mu|&lt;\dfrac {\sigma}{5}, |\hat\sigma-\sigma|&lt;\dfrac \sigma 5\bigg] \geq \dfrac 12.
\end{equation*}\]</span></p>
<p>Por independencia de <span class="math inline">\(\bar X_n\)</span> y <span class="math inline">\(\hat\sigma^2_n\)</span>,
<span class="math display">\[p= \mathbb P \bigg[|\hat\mu-\mu|&lt;\dfrac \sigma5\bigg] \mathbb P \bigg[|\hat\sigma-\sigma|&lt;\dfrac \sigma5\bigg]\]</span></p>
<p>Por un lado,
<span class="math display">\[\mathbb P \bigg[|\hat\mu-\mu|&lt;\dfrac \sigma5\bigg] = \mathbb P \bigg[-\dfrac{\sqrt n}5\leq \underbrace{\dfrac{\sqrt{n}(\hat\mu-\mu)}\sigma}_{N(0,1)} &lt;\dfrac {\sqrt n}{5}\bigg] = \Phi\left(\dfrac{\sqrt n}{5}\right)-\Phi\left(-\dfrac{\sqrt n}{5}\right).\]</span></p>
<p>Además,</p>
<p><span class="math display">\[\begin{align*}
\mathbb P \bigg[|\hat\sigma-\sigma|&lt;\dfrac \sigma5\bigg]
=&amp;\mathbb P \bigg[-\dfrac \sigma 5 &lt; \hat\sigma-\sigma&lt;\dfrac \sigma5\bigg] \\
=&amp;\mathbb P \bigg[-\dfrac{\sigma}{5} +\sigma &lt; \hat\sigma&lt;\dfrac \sigma5 +\sigma\bigg] \\
=&amp;\mathbb P \bigg[-\dfrac 45 \sigma &lt; \hat\sigma&lt;\dfrac 65\sigma\bigg] \\
=&amp;\mathbb P \bigg[-\dfrac 45 &lt; \dfrac{\hat\sigma}{\sigma}&lt;\dfrac 65\bigg] \\
=&amp;\mathbb P \bigg[\left(-\dfrac 45\right)^2 &lt; \dfrac{\hat{\sigma}^2}{\sigma^2}&lt;\left(\dfrac 65\right)^2\bigg] \\
=&amp;\mathbb P \bigg[0.64n &lt; \dfrac{\hat{n\sigma}^2}{\sigma^2} &lt;1.44n\bigg] \\
=&amp; F_{\chi^2_{n-1}}(1.44n)-F_{\chi^2_{n-1}}(0.64n).
\end{align*}\]</span></p>
<p>Estime <span class="math inline">\(n\)</span> de manera que
<span class="math display">\[\bigg[1-2\Phi\left(-\dfrac{\sqrt n}{5}\right)\bigg][F_{\chi^2_{n-1}}(1.44n)-F_{\chi^2_{n-1}}(0.64n)] \geq \dfrac 12.\]</span></p>
<p>Se resuelve numéricamente, y si <span class="math inline">\(n=21\)</span> se cumple.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="distribución-muestral-de-un-estadístico.html#cb107-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">40</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)), <span class="kw">aes</span>(x)) <span class="op">+</span></span>
<span id="cb107-2"><a href="distribución-muestral-de-un-estadístico.html#cb107-2"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dchisq, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">df =</span> <span class="dv">5</span>), <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;05 grados de libertad&quot;</span>)) <span class="op">+</span></span>
<span id="cb107-3"><a href="distribución-muestral-de-un-estadístico.html#cb107-3"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dchisq, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">df =</span> <span class="dv">10</span>), <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;10 grados de libertad&quot;</span>)) <span class="op">+</span></span>
<span id="cb107-4"><a href="distribución-muestral-de-un-estadístico.html#cb107-4"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dchisq, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">df =</span> <span class="dv">20</span>), <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;20 grados de libertad&quot;</span>)) <span class="op">+</span></span>
<span id="cb107-5"><a href="distribución-muestral-de-un-estadístico.html#cb107-5"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;&quot;</span>) <span class="op">+</span></span>
<span id="cb107-6"><a href="distribución-muestral-de-un-estadístico.html#cb107-6"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb107-7"><a href="distribución-muestral-de-un-estadístico.html#cb107-7"></a><span class="st">  </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/05-distribucion-muestral-1-1.svg" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="distribución-t" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Distribución <span class="math inline">\(t\)</span></h2>
<p><strong>Definición</strong>. Sea <span class="math inline">\(Y\)</span> y <span class="math inline">\(Z\)</span> dos variables independientes tal que <span class="math inline">\(Y\sim \chi^2_m\)</span> y <span class="math inline">\(Z\sim N(0,1)\)</span>. Si
<span class="math display">\[X := \dfrac Z{\sqrt{\dfrac Ym}},\]</span>
tiene una distribución <strong><span class="math inline">\(t\)</span> de Student</strong> con <span class="math inline">\(m\)</span> grados de libertad. Tiene como densidad
<span class="math display">\[f_X(x) = \dfrac{\Gamma\left(\dfrac{m+1}2\right)}{\sqrt{m\pi}\Gamma\left(\dfrac m2 \right)}\left(1+\dfrac{x^2}m\right)^{-\frac{m+1}2}, \quad x\in \mathbb R.\]</span></p>
<p><strong>Propiedades</strong>:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(f_X\)</span> es simétrica.</p></li>
<li><p>La media de <span class="math inline">\(X\)</span> no existe si <span class="math inline">\(m\leq 1\)</span>. Si la media existe, es 0.</p></li>
<li><p>Las colas de una <span class="math inline">\(t\)</span> de Student son más pesadas que una <span class="math inline">\(N(0,1)\)</span>.</p></li>
<li><p>Si <span class="math inline">\(m\)</span> es entero, los primeros <span class="math inline">\(m-1\)</span> momentos de <span class="math inline">\(X\)</span> existen y no hay momentos de orden superior.</p></li>
<li><p>Si <span class="math inline">\(m&gt;2\)</span>, <span class="math inline">\(\text{Var}\left(X \right)=\dfrac m{m-2}\)</span>.</p></li>
<li><p>Si <span class="math inline">\(m=1\)</span>, <span class="math inline">\(X\sim \text{Cauchy}\)</span>.</p></li>
<li><p><strong>Ejercicio</strong>: <span class="math inline">\(f_x(x)\xrightarrow[m\to \infty]{}\Phi(x)\)</span> (sirve como aproximación). La discrepancia de ambas está en la cola y se disipa cuando <span class="math inline">\(m\)</span> es grande.</p></li>
</ol>
<p>Recuerde que, por el teorema 8.3.1, <span class="math inline">\(\bar X_n\)</span> y <span class="math inline">\(Y=\dfrac{n\hat\sigma^2}{\sigma}\)</span> son independientes, con <span class="math inline">\(\bar X_n \sim N\left(\mu, \dfrac{\sigma^2}{n}\right)\)</span> y <span class="math inline">\(Y\sim \chi^2_{n-1}\)</span>. Además,
<span class="math display">\[Z = \sqrt n\dfrac{\bar X_n-\mu}{\sigma} \sim N(0,1).\]</span></p>
<p>Sea</p>
<p><span class="math display">\[T = \dfrac Z{\sqrt{\dfrac Y{n-1}}} = \dfrac{\sqrt n \dfrac{\bar X_n-\mu}{\sigma}} {\sqrt{\dfrac{\dfrac{n\hat\sigma^2}{\sigma^2}}{n-1}}} = \dfrac{\bar X_n-\mu}{\sqrt{\dfrac{\hat\sigma}{n-1}}}\]</span>
el cual no depende de <span class="math inline">\(\sigma\)</span>.</p>
<p><strong>Teorema</strong>. Si <span class="math inline">\(X_1,\dots, X_n \stackrel{i.i.d}{\sim} N(\mu,\sigma^2)\)</span>, defina
<span class="math display">\[\sigma&#39; = \bigg[\dfrac 1{n-1}\sum_{i=1}^n(X_i-\bar X_n)^2\bigg]^\frac 12.\]</span>
Entonces
<span class="math display">\[\dfrac{\sqrt{n}(\bar X_n-\mu)}{\sigma&#39;} \sim t_{n-1}\]</span></p>
<p><strong>Nota</strong>. <span class="math inline">\(\sigma&#39; = \left(\dfrac n{n-1}\right)^\frac 12 \hat\sigma\)</span> (si <span class="math inline">\(n\)</span> es grande, <span class="math inline">\(\sigma&#39; = \hat\sigma\)</span>).</p>
<p><em>Prueba</em>. Sean
<span class="math display">\[S_n^2=\sum_{i=1}^n(X_i-\bar X_n)^2, \quad Z = \sqrt n \dfrac{\bar X_n-\mu}{\sigma}. \]</span>
Dado que <span class="math inline">\(Y = \dfrac{S_n^2}{\sigma^2}\sim \chi^2_{n-1}\)</span>, entonces</p>
<p><span class="math display">\[\begin{align*}
U = \dfrac{Z}{\sqrt{\dfrac Y{n-1}}} &amp; = \dfrac{\dfrac{\sqrt n}\sigma (\bar X_n-\mu)}{\sqrt{\dfrac{S_n^2}{\sigma^2(n-1)}}} \\ &amp; = \dfrac{\sqrt n (\bar X_n-\mu)}{\sqrt{\dfrac{S_n^2}{n-1}}}\\&amp; = \dfrac{\sqrt n (\bar X_n-\mu)}{\sigma&#39;} \sim t_{n-1}.
\end{align*}\]</span></p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="distribución-muestral-de-un-estadístico.html#cb108-1"></a><span class="kw">ggplot</span>(<span class="dt">data =</span> <span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)), <span class="kw">aes</span>(x)) <span class="op">+</span></span>
<span id="cb108-2"><a href="distribución-muestral-de-un-estadístico.html#cb108-2"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>), <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot;Normal(0,1)&quot;</span>)) <span class="op">+</span></span>
<span id="cb108-3"><a href="distribución-muestral-de-un-estadístico.html#cb108-3"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dt, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">df =</span> <span class="dv">1</span>), <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot; t con 01 grados de libertad&quot;</span>)) <span class="op">+</span></span>
<span id="cb108-4"><a href="distribución-muestral-de-un-estadístico.html#cb108-4"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dt, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">df =</span> <span class="dv">5</span>), <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot; t con 05 grados de libertad&quot;</span>)) <span class="op">+</span></span>
<span id="cb108-5"><a href="distribución-muestral-de-un-estadístico.html#cb108-5"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dt, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">df =</span> <span class="dv">10</span>), <span class="kw">aes</span>(<span class="dt">color =</span> <span class="st">&quot; t con 10 grados de libertad&quot;</span>)) <span class="op">+</span></span>
<span id="cb108-6"><a href="distribución-muestral-de-un-estadístico.html#cb108-6"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;&quot;</span>) <span class="op">+</span></span>
<span id="cb108-7"><a href="distribución-muestral-de-un-estadístico.html#cb108-7"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">breaks =</span> <span class="ot">NULL</span>) <span class="op">+</span></span>
<span id="cb108-8"><a href="distribución-muestral-de-un-estadístico.html#cb108-8"></a><span class="st">  </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="Notas-Curso-Estadistica_files/figure-html/05-distribucion-muestral-2-1.svg" width="100%" style="display: block; margin: auto;" /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estadísticos-suficientes-y-criterio-de-factorización.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intervalos-de-confianza.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica-parte-1/edit/master/05-distribucion-muestral.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica-parte-1/blob/master/05-distribucion-muestral.Rmd",
"text": null
},
"download": ["Notas-Curso-Estadistica.pdf"],
"toc": {
"collapse": "subsection"
},
"toc_depth": 5
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
